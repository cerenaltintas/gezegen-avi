"""
ğŸ§ª AI Explainability Test Paketi
XAI Ã¶zelliklerinin test edilmesi
"""

import sys
import numpy as np
import pandas as pd

# Test verisi
def create_test_data():
    """Test iÃ§in Ã¶rnek veri oluÅŸtur"""
    features = {
        'koi_period': 5.7,
        'koi_depth': 615.8,
        'koi_duration': 2.95,
        'koi_ror': 0.0174,
        'koi_srho': 4.11,
        'koi_prad': 1.89,
        'koi_teq': 1284.0,
        'koi_insol': 62.3,
        'koi_steff': 5455.0,
        'koi_slogg': 4.467,
        'koi_srad': 0.927,
        'koi_impact': 0.146,
        'koi_model_snr': 35.8,
        'koi_tce_plnt_num': 1,
        'koi_fpflag_nt': 0,
        'koi_fpflag_ss': 0,
        'koi_fpflag_co': 0,
        'koi_fpflag_ec': 0
    }
    return features

def test_explainability_module():
    """Explainability modÃ¼lÃ¼nÃ¼ test et"""
    print("=" * 70)
    print("ğŸ§  AI EXPLAINABILITY MODULE TEST")
    print("=" * 70)
    
    try:
        from explainability import (
            ExplainabilityEngine,
            create_decision_narrative,
            create_shap_waterfall_plotly,
            create_feature_importance_comparison,
            create_decision_path_visualization
        )
        print("âœ… explainability modÃ¼lÃ¼ baÅŸarÄ±yla iÃ§e aktarÄ±ldÄ±")
    except Exception as e:
        print(f"âŒ Ä°Ã§e aktarma hatasÄ±: {e}")
        return False
    
    # Mock verilerle test
    print("\nğŸ“Š Test 1: Karar AnlatÄ±sÄ± OluÅŸturma")
    try:
        test_explanation = {
            'prediction': True,
            'confidence': 0.95,
            'probability': 0.92,
            'shap_analysis': {
                'top_features': [
                    {'name': 'koi_period', 'shap_value': 0.45, 'direction': 'positive', 'rank': 1},
                    {'name': 'koi_depth', 'shap_value': -0.23, 'direction': 'negative', 'rank': 2}
                ],
                'total_positive_impact': 0.75,
                'total_negative_impact': -0.25
            },
            'decision_rules': [
                {
                    'feature': 'koi_period',
                    'value': 5.7,
                    'status': 'optimal',
                    'impact': 'positive',
                    'optimal_range': (5, 100)
                }
            ],
            'confidence_factors': {
                'confidence_level': 0.95,
                'probability_margin': 0.45,
                'factors': [
                    {'factor': 'YÃ¼ksek GÃ¼ven', 'description': 'Model Ã§ok emin', 'impact': 'positive'}
                ]
            },
            'what_if_analysis': [],
            'feature_contribution': None,
            'similar_cases': None
        }
        
        narrative = create_decision_narrative(test_explanation)
        print("âœ… Karar anlatÄ±sÄ± baÅŸarÄ±yla oluÅŸturuldu")
        print("\nÃ–rnek AnlatÄ±:")
        print("-" * 70)
        print(narrative[:300] + "...")
        print("-" * 70)
        
    except Exception as e:
        print(f"âŒ Karar anlatÄ±sÄ± hatasÄ±: {e}")
        return False
    
    print("\nğŸ“ˆ Test 2: Plotly GÃ¶rselleÅŸtirme FonksiyonlarÄ±")
    try:
        # Mock SHAP deÄŸerleri
        shap_values = np.array([0.5, -0.3, 0.2, -0.1, 0.4, 0.15, -0.25, 0.35, -0.05, 0.1])
        base_value = 0.0
        features = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
        feature_names = [f'feature_{i}' for i in range(10)]
        
        # Waterfall plot
        waterfall_fig = create_shap_waterfall_plotly(
            shap_values, base_value, features, feature_names, max_display=5
        )
        print("âœ… SHAP Waterfall plot oluÅŸturuldu")
        
        # Feature importance comparison
        model_importance = np.random.rand(10)
        shap_importance = np.abs(shap_values)
        
        comp_fig = create_feature_importance_comparison(
            model_importance, shap_importance, feature_names, top_n=5
        )
        print("âœ… Ã–zellik karÅŸÄ±laÅŸtÄ±rma grafiÄŸi oluÅŸturuldu")
        
    except Exception as e:
        print(f"âŒ GÃ¶rselleÅŸtirme hatasÄ±: {e}")
        return False
    
    print("\nğŸ¯ Test 3: Karar Yolu GÃ¶rselleÅŸtirmesi")
    try:
        decision_path_fig = create_decision_path_visualization(test_explanation)
        if decision_path_fig:
            print("âœ… Karar yolu grafiÄŸi oluÅŸturuldu")
        else:
            print("âš ï¸ Karar yolu grafiÄŸi None dÃ¶ndÃ¼ (normal olabilir)")
    except Exception as e:
        print(f"âŒ Karar yolu gÃ¶rselleÅŸtirme hatasÄ±: {e}")
        return False
    
    print("\n" + "=" * 70)
    print("âœ… TÃœM TESTLER BAÅARIYLA TAMAMLANDI!")
    print("=" * 70)
    
    return True

def test_integration():
    """Streamlit entegrasyonunu test et"""
    print("\n" + "=" * 70)
    print("ğŸ”— STREAMLIT ENTEGRASYON TESTI")
    print("=" * 70)
    
    try:
        # Streamlit iÃ§e aktarma kontrolÃ¼
        print("\nğŸ“¦ Gerekli paketleri kontrol ediliyor...")
        
        required_packages = [
            'streamlit',
            'plotly',
            'shap',
            'lime',
            'numpy',
            'pandas',
            'matplotlib'
        ]
        
        for package in required_packages:
            try:
                __import__(package)
                print(f"  âœ… {package}")
            except ImportError:
                print(f"  âŒ {package} - YÃ¼klenmemiÅŸ!")
                return False
        
        print("\nâœ… TÃ¼m gerekli paketler mevcut")
        
    except Exception as e:
        print(f"âŒ Entegrasyon testi hatasÄ±: {e}")
        return False
    
    return True

def print_feature_summary():
    """XAI Ã¶zelliklerinin Ã¶zetini yazdÄ±r"""
    print("\n" + "=" * 70)
    print("ğŸ“š AI EXPLAINABILITY Ã–ZELLÄ°KLERÄ° Ã–ZETÄ°")
    print("=" * 70)
    
    features = {
        "SHAP Analizi": [
            "âœ… Ä°nteraktif Waterfall Plot",
            "âœ… Ã–zellik katkÄ± tablosu",
            "âœ… Pozitif/Negatif etki Ã¶zeti",
            "âœ… Matplotlib yedek gÃ¶rselleÅŸtirme"
        ],
        "Ã–zellik KatkÄ±larÄ±": [
            "âœ… AÄŸÄ±rlÄ±klÄ± katkÄ± analizi",
            "âœ… Model Ã¶nem derecesi karÅŸÄ±laÅŸtÄ±rmasÄ±",
            "âœ… DetaylÄ± katkÄ± tablosu",
            "âœ… Interaktif grafikler"
        ],
        "Karar KurallarÄ±": [
            "âœ… EÅŸik deÄŸeri kontrolÃ¼",
            "âœ… Optimal aralÄ±k analizi",
            "âœ… Durum gÃ¶rselleÅŸtirmesi",
            "âœ… Kural detaylarÄ±"
        ],
        "What-If Analizi": [
            "âœ… Senaryo simÃ¼lasyonu",
            "âœ… Ä°nteraktif slider",
            "âœ… DeÄŸiÅŸim yÃ¼zdesi hesaplama",
            "âœ… Alternatif deÄŸer Ã¶nerileri"
        ],
        "KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz": [
            "âœ… Bilinen gezegenlerle karÅŸÄ±laÅŸtÄ±rma",
            "âœ… GÃ¶rsel karÅŸÄ±laÅŸtÄ±rma grafikleri",
            "âœ… GÃ¼ven faktÃ¶rÃ¼ analizi",
            "âœ… Referans deÄŸerler"
        ],
        "AnlatÄ±sal AÃ§Ä±klamalar": [
            "âœ… Ä°nsan tarafÄ±ndan okunabilir aÃ§Ä±klamalar",
            "âœ… Karar Ã¶zetleri",
            "âœ… Etki dengesi analizi",
            "âœ… GÃ¼venilirlik deÄŸerlendirmesi"
        ]
    }
    
    for category, items in features.items():
        print(f"\nğŸ¯ {category}:")
        for item in items:
            print(f"   {item}")
    
    print("\n" + "=" * 70)
    print("ğŸ“Š Ä°statistikler:")
    print(f"   â€¢ Toplam Kategori: {len(features)}")
    print(f"   â€¢ Toplam Ã–zellik: {sum(len(items) for items in features.values())}")
    print(f"   â€¢ GÃ¶rselleÅŸtirme: 10+ interaktif grafik")
    print(f"   â€¢ Analiz DerinliÄŸi: 5 seviye")
    print("=" * 70)

if __name__ == "__main__":
    print("\nğŸ§ª AI EXPLAINABILITY TEST PAKETÄ°\n")
    
    # Testleri Ã§alÄ±ÅŸtÄ±r
    test_results = []
    
    print("1ï¸âƒ£ Explainability ModÃ¼lÃ¼ Testi")
    test_results.append(("Explainability Module", test_explainability_module()))
    
    print("\n2ï¸âƒ£ Entegrasyon Testi")
    test_results.append(("Integration", test_integration()))
    
    # Ã–zellikleri gÃ¶ster
    print_feature_summary()
    
    # SonuÃ§ Ã¶zeti
    print("\n" + "=" * 70)
    print("ğŸ“Š TEST SONUÃ‡ Ã–ZETÄ°")
    print("=" * 70)
    
    for test_name, result in test_results:
        status = "âœ… BAÅARILI" if result else "âŒ BAÅARISIZ"
        print(f"{test_name}: {status}")
    
    all_passed = all(result for _, result in test_results)
    
    print("\n" + "=" * 70)
    if all_passed:
        print("ğŸ‰ TÃœM TESTLER BAÅARIYLA GEÃ‡TÄ°!")
        print("âœ… AI Explainability Ã¶zellikleri kullanÄ±ma hazÄ±r")
    else:
        print("âš ï¸ BAZI TESTLER BAÅARISIZ OLDU")
        print("âŒ LÃ¼tfen hatalarÄ± kontrol edin")
    print("=" * 70 + "\n")
    
    sys.exit(0 if all_passed else 1)
