"""
ğŸŒŒ Ã–tegezegen KeÅŸif Sistemi - Streamlit ArayÃ¼zÃ¼
XAI (Explainable AI) ile GeliÅŸmiÅŸ Analiz ve AÃ§Ä±klanabilir Tahminler
"""

import os
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import joblib
import shap
from lime import lime_tabular
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json
import base64
from io import BytesIO
from pathlib import Path
import hashlib
import warnings
warnings.filterwarnings('ignore')

from data_generator import (
    ExoplanetDataGenerator,
    load_reference_dataset,
    prepare_features_from_dataframe,
)
from nasa_api import get_latest_dataframe
from explainability import (
    ExplainabilityEngine,
    create_decision_narrative,
    create_shap_waterfall_plotly,
    create_feature_importance_comparison,
    create_decision_path_visualization
)
from gemini_explainer import GeminiExplainer

# Gemini API AnahtarÄ± (gÃ¼venli bir ÅŸekilde saklanmalÄ±)
GEMINI_API_KEY = "AIzaSyCX0vQ1MfSAFPfYsrZXMiXbVBp5fRGV6Eg"

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="ğŸŒŒ Ã–tegezegen KeÅŸif Sistemi",
    page_icon="ğŸŒŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Stilleri
st.markdown("""
    <style>
    :root {
        --gradient-bg: radial-gradient(circle at 25% 15%, #1e3a8a 0%, #0b1220 45%, #020617 100%);
        --card-bg: rgba(15, 23, 42, 0.78);
        --card-border: rgba(148, 163, 184, 0.18);
        --chip-bg: rgba(148, 163, 184, 0.14);
        --text-primary: #f8fafc;
        --text-secondary: #cbd5f5;
        --accent: #38bdf8;
        --accent-strong: #2563eb;
    }
    .stApp {
        background: var(--gradient-bg);
        color: var(--text-primary);
        font-family: 'Segoe UI', 'Inter', sans-serif;
    }
    .main {
        background: transparent;
    }
    [data-testid="stSidebar"] {
        background: rgba(2, 6, 23, 0.88);
        backdrop-filter: blur(18px);
        border-right: 1px solid rgba(148, 163, 184, 0.12);
    }
    [data-testid="stSidebar"] * {
        color: #e2e8f0 !important;
    }
    .hero {
        padding: 36px 42px;
        border-radius: 22px;
        background: linear-gradient(120deg, rgba(37, 99, 235, 0.25), rgba(124, 58, 237, 0.22));
        border: 1px solid rgba(148, 163, 184, 0.18);
        backdrop-filter: blur(24px);
    }
    .hero-title {
        font-size: 2.6rem;
        font-weight: 700;
        letter-spacing: -0.03em;
        margin-bottom: 10px;
        color: var(--text-primary);
    }
    .hero-subtitle {
        color: var(--text-secondary);
        font-size: 1.05rem;
        max-width: 620px;
        line-height: 1.6;
        margin-bottom: 18px;
    }
    .tagline {
        color: #60a5fa;
        text-transform: uppercase;
        font-size: 0.75rem;
        letter-spacing: 0.28em;
        font-weight: 600;
        display: inline-block;
        margin-bottom: 16px;
    }
    .hero-badges {
        display: flex;
        gap: 14px;
        flex-wrap: wrap;
    }
    .badge {
        background: rgba(148, 163, 184, 0.16);
        border: 1px solid rgba(148, 163, 184, 0.25);
        border-radius: 999px;
        padding: 8px 16px;
        color: #cbd5f5;
        font-size: 0.85rem;
        display: inline-flex;
        gap: 8px;
        align-items: center;
    }
    .cta-button {
        background: linear-gradient(120deg, #2563eb, #7c3aed);
        color: var(--text-primary);
        padding: 12px 22px;
        border-radius: 14px;
        text-decoration: none;
        font-weight: 600;
        display: inline-flex;
        gap: 10px;
        align-items: center;
        margin-top: 20px;
        transition: transform 0.18s ease, box-shadow 0.18s ease;
    }
    .cta-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 18px 45px rgba(37, 99, 235, 0.28);
    }
    .metric-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
        gap: 18px;
        margin: 28px 0 8px;
    }
    .metric-card {
        background: var(--card-bg);
        border-radius: 18px;
        border: 1px solid var(--card-border);
        padding: 22px;
        color: var(--text-secondary);
    }
    .metric-card h2 {
        margin-bottom: 10px;
        font-size: 1rem;
        color: var(--text-primary);
        font-weight: 600;
    }
    .metric-value {
        font-size: 2.1rem;
        font-weight: 600;
        color: var(--accent);
        margin-bottom: 6px;
    }
    .metric-delta {
        font-size: 0.85rem;
        color: #38ef7d;
        text-transform: uppercase;
        letter-spacing: 0.08em;
    }
    .dashboard-card {
        background: var(--card-bg);
        border: 1px solid var(--card-border);
        border-radius: 20px;
        padding: 26px 28px;
        margin-bottom: 22px;
        color: var(--text-secondary);
    }
    .section-title {
        color: var(--text-primary);
        font-size: 1.3rem;
        font-weight: 650;
        margin-bottom: 6px;
    }
    .section-subtitle {
        color: var(--text-secondary);
        font-size: 0.96rem;
        margin-bottom: 18px;
    }
    .card-list {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
        gap: 18px;
        margin-top: 12px;
    }
    .card-item {
        background: rgba(15, 23, 42, 0.68);
        border-radius: 18px;
        padding: 22px;
        border: 1px solid rgba(148, 163, 184, 0.16);
        color: var(--text-secondary);
    }
    .card-item h3 {
        color: var(--text-primary);
        font-size: 1.05rem;
        margin-bottom: 10px;
    }
    .info-chip {
        display: inline-flex;
        align-items: center;
        gap: 8px;
        padding: 10px 14px;
        background: rgba(148, 163, 184, 0.12);
        border-radius: 12px;
        color: var(--text-secondary);
        margin-right: 8px;
        margin-bottom: 10px;
    }
    .info-box, .warning-box, .success-box {
        background: rgba(15, 23, 42, 0.65);
        border-radius: 16px;
        padding: 18px 20px;
        border-left: 4px solid var(--accent);
        border: 1px solid rgba(148, 163, 184, 0.14);
        color: var(--text-secondary);
    }
    .warning-box { border-left-color: #f97316; }
    .success-box { border-left-color: #34d399; }
    .info-box h3, .warning-box h3, .success-box h3 {
        color: var(--text-primary);
    }
    .prediction-banner {
        border-radius: 18px;
        padding: 26px 24px;
        margin: 20px 0 28px;
        text-align: center;
        font-weight: 600;
        font-size: 1.35rem;
        border: 1px solid rgba(148, 163, 184, 0.14);
        color: var(--text-primary);
    }
    .prediction-banner.success {
        background: linear-gradient(120deg, rgba(22, 163, 74, 0.22), rgba(34, 197, 94, 0.18));
        border-left: 6px solid #22c55e;
    }
    .prediction-banner.danger {
        background: linear-gradient(120deg, rgba(239, 68, 68, 0.22), rgba(251, 113, 133, 0.18));
        border-left: 6px solid #f97316;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 12px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: rgba(148, 163, 184, 0.12);
        border-radius: 12px;
        padding: 10px 18px;
        color: var(--text-secondary);
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(130deg, rgba(37, 99, 235, 0.45), rgba(124, 58, 237, 0.45));
        color: var(--text-primary);
    }
    .streamlit-expanderHeader {
        color: var(--text-primary) !important;
        font-weight: 600;
    }
    .streamlit-expanderContent {
        background: rgba(15, 23, 42, 0.55);
        border-radius: 0 0 16px 16px;
    }
    .stButton > button {
        border-radius: 14px;
        height: 46px;
        font-weight: 600;
        background: linear-gradient(120deg, #2563eb, #7c3aed);
        border: none;
        color: var(--text-primary);
    }
    .stButton > button:hover {
        opacity: 0.92;
    }
    .stDownloadButton > button {
        border-radius: 12px;
        border: 1px solid rgba(148, 163, 184, 0.26);
        background: rgba(15, 23, 42, 0.72);
        color: var(--text-secondary);
        font-weight: 600;
    }
    .stMetricValue, .stMetricLabel, .stMetricDelta {
        color: var(--text-primary) !important;
    }
    .highlight-text {
        color: var(--accent);
        font-weight: 600;
    }
    .divider {
        margin: 36px 0;
        border-top: 1px solid rgba(148, 163, 184, 0.1);
    }
    </style>
""", unsafe_allow_html=True)


def _resolve_dashboard_token() -> str:
    """Kurumsal panel iÃ§in eriÅŸim anahtarÄ±nÄ± Ã§Ã¶zÃ¼mler."""
    secrets_token = None
    try:
        secrets_token = st.secrets["dashboard_passcode"]
    except Exception:
        secrets_token = None

    env_token = os.environ.get("EXO_DASHBOARD_TOKEN")

    token = secrets_token or env_token or "demo"
    return str(token).strip()


def enforce_access_control() -> None:
    """Panel eriÅŸimini basit bir eriÅŸim kodu ile sÄ±nÄ±rlar."""
    required_token = _resolve_dashboard_token()

    if required_token.lower() == "demo":
        return

    if "exo_dashboard_authenticated" not in st.session_state:
        st.session_state.exo_dashboard_authenticated = False

    if st.session_state.exo_dashboard_authenticated:
        return

    st.sidebar.markdown("### ğŸ” GÃ¼venli EriÅŸim")
    entered_code = st.sidebar.text_input(
        "Kurumsal eriÅŸim kodu", type="password", key="access_code"
    )
    login_clicked = st.sidebar.button("GiriÅŸ yap", key="access_code_button")

    if login_clicked:
        if entered_code == required_token:
            st.session_state.exo_dashboard_authenticated = True
            st.sidebar.success("DoÄŸrulama tamamlandÄ±.")
        else:
            st.sidebar.error("Kod doÄŸrulanamadÄ±. LÃ¼tfen tekrar deneyin.")

    if not st.session_state.exo_dashboard_authenticated:
        st.warning("Yetkili eriÅŸim gereklidir. GeÃ§erli kodu girene kadar panel gizlidir.")
        st.stop()


@st.cache_data(show_spinner=False)
def fetch_live_catalog(mission: str, limit: int, force_refresh: bool) -> pd.DataFrame:
    """NASA Exoplanet Archive'dan canlÄ± verileri getirir."""
    df = get_latest_dataframe(mission=mission, limit=limit, force_refresh=force_refresh)
    df = df.copy()
    df["source_mission"] = mission.upper()
    return df


def _align_feature_frame(features_df: pd.DataFrame, feature_names: list[str]) -> pd.DataFrame:
    """Modelde kullanÄ±lan Ã¶zelliklerin sÄ±rasÄ±nÄ± ve bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ saÄŸlar."""
    aligned = features_df.copy()
    missing_cols = [col for col in feature_names if col not in aligned.columns]
    for col in missing_cols:
        aligned[col] = 0
    aligned = aligned[feature_names]
    aligned = aligned.replace([np.inf, -np.inf], np.nan)
    aligned = aligned.fillna(0)
    return aligned


def score_catalog(
    df: pd.DataFrame,
    model,
    scaler,
    feature_names: list[str],
    anomaly_detector=None,
):
    """Veri Ã§erÃ§evesini model ve anomali dedektÃ¶rÃ¼ ile skorlar."""
    features, labels = prepare_features_from_dataframe(df)
    aligned_features = _align_feature_frame(features, feature_names)
    X_scaled = scaler.transform(aligned_features)
    probabilities = model.predict_proba(X_scaled)[:, 1]
    predictions = model.predict(X_scaled)

    scored_df = df.copy()
    scored_df["model_probability"] = probabilities
    scored_df["model_prediction"] = np.where(predictions == 1, "CONFIRMED", "OTHER")

    novelty_scores = None
    novelty_flags = None
    if anomaly_detector is not None:
        novelty_scores = anomaly_detector.decision_function(X_scaled)
        novelty_flags = anomaly_detector.predict(X_scaled)
        scored_df["novelty_score"] = novelty_scores
        scored_df["is_novel_candidate"] = novelty_flags == -1
    else:
        scored_df["novelty_score"] = np.nan
        scored_df["is_novel_candidate"] = False

    return {
        "scored": scored_df,
        "features": aligned_features,
        "labels": labels,
        "scaled": X_scaled,
        "probabilities": probabilities,
        "novelty_scores": novelty_scores,
        "novelty_flags": novelty_flags,
    }

# Model ve scaler'Ä± yÃ¼kle
@st.cache_resource
def load_models():
    """Model, scaler ve Ã¶zellik isimlerini yÃ¼kle"""
    try:
        model = joblib.load('exoplanet_model.pkl')
        scaler = joblib.load('scaler.pkl')
        feature_names = joblib.load('feature_names.pkl')
        anomaly_path = Path('anomaly_detector.pkl')
        anomaly_detector = None
        if anomaly_path.exists():
            anomaly_detector = joblib.load(anomaly_path)

        # SHAP Explainer'Ä± oluÅŸtur
        background_df = load_default_reference_dataframe().drop(columns='is_exoplanet')
        background_aligned = _align_feature_frame(background_df, feature_names)
        explainer = shap.TreeExplainer(model, data=background_aligned.sample(min(200, len(background_aligned)), random_state=42))

        return model, scaler, feature_names, explainer, anomaly_detector
    except Exception as e:
        st.error(f"âŒ Model dosyalarÄ± yÃ¼klenemedi: {e}")
        st.info("â„¹ï¸ LÃ¼tfen Ã¶nce 'python main.py' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return None, None, None, None, None


@st.cache_data(show_spinner=False)
def load_default_reference_dataframe(path: str = 'cumulative_2025.10.04_09.55.40.csv'):
    data_path = Path(path)
    if not data_path.exists():
        raise FileNotFoundError(
            f"VarsayÄ±lan veri seti bulunamadÄ±: {data_path.resolve()}"
        )
    return load_reference_dataset(data_path)

def anonymize_sensitive_columns(df, sensitive_columns=None):
    """
    Veri setindeki hassas sÃ¼tunlarÄ± anonimleÅŸtirir.
    
    Args:
        df: Pandas DataFrame
        sensitive_columns: AnonimleÅŸtirilecek sÃ¼tun listesi. 
                          None ise otomatik algÄ±lama yapÄ±lÄ±r.
    
    Returns:
        AnonimleÅŸtirilmiÅŸ DataFrame ve anonimleÅŸtirme raporu
    """
    df_anon = df.copy()
    anonymization_report = {
        'total_columns': len(df.columns),
        'anonymized_columns': [],
        'method_used': {}
    }
    
    # Otomatik hassas sÃ¼tun tespiti
    if sensitive_columns is None:
        sensitive_columns = []
        # Ä°sim, ID, email, koordinat gibi hassas bilgiler iÃ§erebilecek sÃ¼tunlarÄ± tespit et
        sensitive_keywords = ['name', 'id', 'email', 'address', 'phone', 
                             'ra', 'dec', 'coordinate', 'location', 
                             'kepid', 'kepoi']
        
        for col in df.columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in sensitive_keywords):
                sensitive_columns.append(col)
    
    # AnonimleÅŸtirme iÅŸlemleri
    for col in sensitive_columns:
        if col not in df.columns:
            continue
            
        col_type = df[col].dtype
        
        # SayÄ±sal deÄŸerler iÃ§in hash
        if pd.api.types.is_numeric_dtype(col_type):
            df_anon[col] = df[col].apply(
                lambda x: int(hashlib.sha256(str(x).encode()).hexdigest()[:8], 16) % 1000000
                if pd.notna(x) else x
            )
            anonymization_report['method_used'][col] = 'numeric_hash'
        
        # String deÄŸerler iÃ§in hash
        elif pd.api.types.is_string_dtype(col_type) or col_type == 'object':
            df_anon[col] = df[col].apply(
                lambda x: f"ANON_{hashlib.sha256(str(x).encode()).hexdigest()[:12].upper()}"
                if pd.notna(x) else x
            )
            anonymization_report['method_used'][col] = 'string_hash'
        
        anonymization_report['anonymized_columns'].append(col)
    
    return df_anon, anonymization_report

def validate_csv_file(uploaded_file):
    """
    YÃ¼klenen dosyanÄ±n CSV formatÄ±nda olduÄŸunu doÄŸrular.
    
    Args:
        uploaded_file: Streamlit UploadedFile objesi
    
    Returns:
        (is_valid, error_message)
    """
    if uploaded_file is None:
        return False, "Dosya yÃ¼klenmedi."
    
    # Dosya uzantÄ±sÄ± kontrolÃ¼
    file_name = uploaded_file.name
    if not file_name.lower().endswith('.csv'):
        return False, f"âŒ GeÃ§ersiz dosya tÃ¼rÃ¼: '{file_name}'. Sadece CSV dosyalarÄ± kabul edilir."
    
    # Dosya boyutu kontrolÃ¼ (maksimum 100MB)
    max_size_mb = 100
    file_size_mb = uploaded_file.size / (1024 * 1024)
    if file_size_mb > max_size_mb:
        return False, f"âŒ Dosya Ã§ok bÃ¼yÃ¼k: {file_size_mb:.2f}MB. Maksimum {max_size_mb}MB olmalÄ±dÄ±r."
    
    # Ä°Ã§erik kontrolÃ¼ - CSV formatÄ±nÄ± doÄŸrula
    try:
        # DosyayÄ± okumayÄ± dene
        uploaded_file.seek(0)
        test_df = pd.read_csv(uploaded_file, nrows=5)
        uploaded_file.seek(0)  # Dosya iÅŸaretÃ§isini baÅŸa al
        
        if len(test_df.columns) == 0:
            return False, "âŒ CSV dosyasÄ± geÃ§erli sÃ¼tunlar iÃ§ermiyor."
        
        return True, "âœ… Dosya geÃ§erli."
    
    except pd.errors.EmptyDataError:
        return False, "âŒ CSV dosyasÄ± boÅŸ."
    except pd.errors.ParserError as e:
        return False, f"âŒ CSV ayrÄ±ÅŸtÄ±rma hatasÄ±: {str(e)}"
    except Exception as e:
        return False, f"âŒ Dosya okuma hatasÄ±: {str(e)}"

# Ã–zellik mÃ¼hendisliÄŸi fonksiyonu
def engineer_features(features_dict, feature_names):
    """Ã–zellik mÃ¼hendisliÄŸi uygula"""
    X = pd.DataFrame([features_dict])
    
    # 1. Gezegen-yÄ±ldÄ±z boyut oranÄ±
    if 'koi_prad' in X.columns and 'koi_srad' in X.columns:
        X['planet_star_ratio'] = X['koi_prad'] / (X['koi_srad'] * 109.2)
    
    # 2. Sinyal kalitesi gÃ¶stergesi
    if 'koi_depth' in X.columns and 'koi_model_snr' in X.columns:
        X['signal_quality'] = X['koi_depth'] * X['koi_model_snr']
    
    # 3. YÃ¶rÃ¼nge hÄ±zÄ± tahmini
    if 'koi_period' in X.columns and X['koi_period'].iloc[0] > 0:
        X['orbital_velocity'] = 1 / X['koi_period']
    
    # 4. YanlÄ±ÅŸ pozitif toplam skoru
    fp_flags = ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec']
    available_fp_flags = [f for f in fp_flags if f in X.columns]
    if available_fp_flags:
        X['fp_total_score'] = X[available_fp_flags].sum(axis=1)
    
    # 5. GeÃ§iÅŸ ÅŸekil faktÃ¶rÃ¼
    if 'koi_duration' in X.columns and 'koi_period' in X.columns and X['koi_period'].iloc[0] > 0:
        X['transit_shape_factor'] = X['koi_duration'] / X['koi_period']
    
    # Eksik Ã¶zellikleri 0 ile doldur
    for feature in feature_names:
        if feature not in X.columns:
            X[feature] = 0
    
    # Ã–zellikleri doÄŸru sÄ±rada al
    X = X[feature_names]
    
    # Sonsuz ve NaN deÄŸerleri temizle
    X = X.replace([np.inf, -np.inf], np.nan)
    X = X.fillna(0)
    
    return X

# Tahmin fonksiyonu
def predict_exoplanet(features_dict, model, scaler, feature_names, anomaly_detector=None):
    """Ã–tegezegen tahmini yap"""
    X = engineer_features(features_dict, feature_names)
    
    # Ã–lÃ§eklendir ve tahmin yap
    X_scaled = scaler.transform(X)
    prediction = model.predict(X_scaled)[0]
    probability = model.predict_proba(X_scaled)[0]
    novelty = None
    if anomaly_detector is not None:
        novelty_flag = anomaly_detector.predict(X_scaled)[0]
        novelty_score = anomaly_detector.decision_function(X_scaled)[0]
        novelty = {
            'is_novel_candidate': bool(novelty_flag == -1),
            'novelty_score': float(novelty_score)
        }
    
    return {
        'is_exoplanet': bool(prediction),
        'probability_not_exoplanet': float(probability[0]),
        'probability_exoplanet': float(probability[1]),
        'confidence': float(max(probability)),
        'X_scaled': X_scaled,
        'X_original': X,
        'novelty': novelty
    }

# SHAP aÃ§Ä±klamasÄ±
def get_shap_explanation(model, X_scaled, explainer, feature_names):
    """SHAP deÄŸerlerini hesapla"""
    shap_values = explainer.shap_values(X_scaled)
    return shap_values

# LIME aÃ§Ä±klamasÄ±
def get_lime_explanation(model, X_scaled, X_original, feature_names, scaler):
    """LIME aÃ§Ä±klamasÄ± oluÅŸtur"""
    # LIME explainer oluÅŸtur
    explainer = lime_tabular.LimeTabularExplainer(
        training_data=X_scaled,
        feature_names=feature_names,
        class_names=['Ã–tegezegen DeÄŸil', 'Ã–tegezegen'],
        mode='classification'
    )
    
    # AÃ§Ä±klama Ã¼ret
    exp = explainer.explain_instance(
        X_scaled[0], 
        model.predict_proba,
        num_features=10
    )
    
    return exp

# Ana uygulama
def main():
    # BaÅŸlÄ±k
    enforce_access_control()
    
    # Modelleri yÃ¼kle
    model, scaler, feature_names, explainer, anomaly_detector = load_models()
    feature_names = list(feature_names) if feature_names is not None else []
    
    if model is None:
        st.stop()
    
    # Sidebar - Navigasyon
    with st.sidebar:
        st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/NASA_logo.svg/2449px-NASA_logo.svg.png", width=100)
        st.title("ğŸ“¡ Navigasyon")

        page_definitions = [
            ("home", "ğŸ  Ana Sayfa"),
            ("live", "ğŸ›°ï¸ NASA CanlÄ± AkÄ±ÅŸÄ±"),
            ("predict", "ğŸ”® Tahmin Yap"),
            ("batch", "ğŸ“Š Toplu Analiz"),
            ("synth", "ğŸ§ª Veri Ãœretimi"),
            ("3d_viz", "ğŸŒŒ 3B YÄ±ldÄ±z Sistemi"),
            ("model", "ğŸ§  Model Analizi"),
            ("about", "ğŸ“š HakkÄ±nda"),
        ]
        page_labels = {key: label for key, label in page_definitions}
        page_key = st.radio(
            "Sayfa SeÃ§in:",
            options=[key for key, _ in page_definitions],
            format_func=lambda key: page_labels.get(key, key),
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ Model PerformansÄ±")
        st.metric("DoÄŸruluk", "94.46%", "4.46%")
        st.metric("F1 Skoru", "0.9065", "0.0065")
        st.metric("ROC AUC", "0.9839", "0.0839")
        
        st.markdown("---")
        st.markdown("### ğŸŒŸ Ä°statistikler")
        st.info(f"ğŸ“… **Tarih:** {datetime.now().strftime('%d.%m.%Y')}")
        st.info(f"ğŸ”¢ **Toplam Ã–zellik:** {len(feature_names)}")
        
    # Sayfa yÃ¶nlendirme
    if page_key == "home":
        show_home_page()
    elif page_key == "live":
        show_live_data_page(model, scaler, feature_names, anomaly_detector)
    elif page_key == "predict":
        show_prediction_page(model, scaler, feature_names, explainer, anomaly_detector)
    elif page_key == "batch":
        show_batch_analysis_page(model, scaler, feature_names, anomaly_detector)
    elif page_key == "synth":
        show_data_generation_page()
    elif page_key == "3d_viz":
        show_3d_star_system_page()
    elif page_key == "model":
        show_model_analysis_page(model, scaler, feature_names, anomaly_detector)
    elif page_key == "about":
        show_about_page()

def show_home_page():
    """Ana sayfa"""
    st.markdown("""
        <div class="hero">
            <span class="tagline">gÃ¶rev kontrolÃ¼ â€¢ ileri analitik</span>
            <div class="hero-title" style="margin-bottom:4px;">Ã–tegezegen KeÅŸif Kontrol Paneli</div>
            <p class="hero-subtitle">Profesyonel veri bilimciler iÃ§in tasarlanan panel; doÄŸrulanmÄ±ÅŸ Kepler metrikleri, XAI aÃ§Ä±klamalarÄ± ve sentetik veri Ã¼retimi ile araÅŸtÄ±rma dÃ¶ngÃ¼sÃ¼nÃ¼ hÄ±zlandÄ±rÄ±r.</p>
            <div class="hero-badges">
                <span class="badge">ğŸš€ XGBoost + XAI</span>
                <span class="badge">ğŸ§ª Sentetik veri laboratuvarÄ±</span>
                <span class="badge">ğŸ“¡ SMOTE & Gauss karÄ±ÅŸÄ±mlarÄ±</span>
                <span class="badge">ğŸ›°ï¸ 20+ astrofizik Ã¶zelliÄŸi</span>
                <span class="badge">ğŸ›°ï¸ NASA canlÄ± kataloÄŸu</span>
            </div>
            <a class="cta-button" href="#prediction-anchor">Tahmin modÃ¼lÃ¼ne git â†’</a>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("""
        <div class="section-title" style="margin-top:28px;">Operasyonel gÃ¶stergeler</div>
        <p class="section-subtitle">Son eÄŸitim dÃ¶ngÃ¼sÃ¼nden elde edilen metrikler. Trendler model gÃ¼ncellemeleriyle otomatik yenilenir.</p>
        <div class="metric-grid">
            <div class="metric-card">
                <h2>Model doÄŸruluÄŸu</h2>
                <div class="metric-value">94.46%</div>
                <div class="metric-delta">+4.46% hedefin Ã¼zerinde</div>
                <p>Kepler test kÃ¼mesi performansÄ±</p>
            </div>
            <div class="metric-card">
                <h2>XAI kapsamÄ±</h2>
                <div class="metric-value">23 Ã¶zellik</div>
                <div class="metric-delta">SHAP & LIME destekli</div>
                <p>Her tahmin iÃ§in aÃ§Ä±klanabilirlik katmanÄ±</p>
            </div>
            <div class="metric-card">
                <h2>Sentetik Ã¼retim</h2>
                <div class="metric-value">3K kayÄ±t</div>
                <div class="metric-delta">Hibrit strateji</div>
                <p>Yeni veri akÄ±ÅŸÄ± ile sÃ¼rekli keÅŸif</p>
            </div>
            <div class="metric-card">
                <h2>Sunum gecikmesi</h2>
                <div class="metric-value">&lt; 120 ms</div>
                <div class="metric-delta">GerÃ§ek zamanlÄ± analiz</div>
                <p>Streamlit paneli iÃ§in ortalama render sÃ¼resi</p>
            </div>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("""
        <div class="section-title">Platform modÃ¼lleri</div>
        <p class="section-subtitle">Model eÄŸitiminden sahada karar desteÄŸine kadar tÃ¼m sÃ¼reci tek panelden yÃ¶netin.</p>
        <div class="card-list">
            <div class="card-item">
                <h3>ğŸ”® Tahmin Ä°ÅŸleme</h3>
                <p>Tekil adaylarÄ± saniyeler iÃ§inde deÄŸerlendirip gÃ¼ven skorlarÄ± ve olasÄ±lÄ±klar alÄ±n.</p>
                <div class="info-chip">GerÃ§ek zamanlÄ± SNR analizi</div>
                <div class="info-chip">Ã–znitelik normalizasyonu</div>
            </div>
            <div class="card-item">
                <h3>ğŸ“Š Toplu Analiz</h3>
                <p>CSV yÃ¼kleyerek binlerce adayÄ±n sonuÃ§larÄ±nÄ± ve Ã¶zet istatistikleri tek raporda toplayÄ±n.</p>
                <div class="info-chip">Toplu skor kartÄ±</div>
                <div class="info-chip">Otomatik veri temizleme</div>
            </div>
            <div class="card-item">
                <h3>ğŸ§  Model Analizi</h3>
                <p>KarmaÅŸÄ±klÄ±k matrisi, ROC eÄŸrisi ve Ã¶zellik Ã¶nem daÄŸÄ±lÄ±mÄ± ile model saÄŸlÄ±ÄŸÄ±nÄ± izleyin.</p>
                <div class="info-chip">DetaylÄ± performans paneli</div>
                <div class="info-chip">Ã–zellik katkÄ± raporu</div>
            </div>
            <div class="card-item">
                <h3>ğŸ§ª Sentetik Laboratuvar</h3>
                <p>SMOTE ve Gauss karÄ±ÅŸÄ±mlarÄ±nÄ± harmanlayarak dengeli, fiziksel olarak tutarlÄ± veri Ã¼retilmesini saÄŸlayÄ±n.</p>
                <div class="info-chip">Hedef sÄ±nÄ±f oranÄ± kontrolÃ¼</div>
                <div class="info-chip">AykÄ±rÄ± kÄ±rpma</div>
            </div>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<div class='divider'></div>", unsafe_allow_html=True)

    st.markdown("""
        <div class="section-title">Ã‡alÄ±ÅŸma akÄ±ÅŸÄ±</div>
        <p class="section-subtitle">Her modÃ¼l veri bilimi sÃ¼recinin belirli bir aÅŸamasÄ±nÄ± hÄ±zlandÄ±rmak Ã¼zere tasarlandÄ±.</p>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["1ï¸âƒ£ Tahmin", "2ï¸âƒ£ Toplu Analiz", "3ï¸âƒ£ Ä°zleme"])

    with tab1:
        st.markdown("""
            - Sol menÃ¼den **"ğŸ”® Tahmin Yap"** sekmesini aÃ§Ä±n.
            - Gezegen parametrelerini girin veya varsayÄ±lan senaryoyu kullanÄ±n.
            - **"ğŸš€ Tahmin Et"** butonunu tetikleyin; sonuÃ§lar olasÄ±lÄ±k, gÃ¼ven ve XAI katkÄ±larÄ±yla birlikte gelir.
            - SHAP waterfall ve LIME analizine gÃ¶re kritik Ã¶zellikleri inceleyin.
        """)

    with tab2:
        st.markdown("""
            - **"ğŸ“Š Toplu Analiz"** bÃ¶lÃ¼mÃ¼nden CSV dosyanÄ±zÄ± iÃ§eri alÄ±n.
            - Otomatik normalizasyon ve eksik deÄŸer iyileÅŸtirmesi tamamlandÄ±ktan sonra toplu tahminler Ã¼retilir.
            - Ã‡Ä±ktÄ± raporlarÄ±nÄ± indirerek araÅŸtÄ±rma notlarÄ±nÄ±za ekleyin.
        """)

    with tab3:
        st.markdown("""
            - **"ğŸ§  Model Analizi"** sekmesi ile Ã¼retim modelinin saÄŸlÄ±ÄŸÄ±nÄ± izleyin.
            - Zaman iÃ§inde doÄŸruluk eÄŸilimlerini takip edin ve kritik durumlarda yeniden eÄŸitim tetikleyin.
            - Sentetik laboratuvar modÃ¼lÃ¼yle dengeli veri setleri oluÅŸturarak modelinizi gÃ¼ncel tutun.
        """)

def show_prediction_page(model, scaler, feature_names, explainer, anomaly_detector):
    """Tahmin sayfasÄ±"""
    st.markdown("<div id='prediction-anchor'></div>", unsafe_allow_html=True)
    st.header("ğŸ”® Ã–tegezegen Tahmini")
    st.markdown("Gezegen Ã¶zelliklerini girerek Ã¶tegezegen olup olmadÄ±ÄŸÄ±nÄ± tahmin edin.")
    
    # GiriÅŸ modu seÃ§imi
    input_mode = st.radio("GiriÅŸ Modu:", ["ğŸ“ Basit Mod (Ana Ã–zellikler)", "ğŸ”¬ GeliÅŸmiÅŸ Mod (TÃ¼m Ã–zellikler)"], horizontal=True)
    
    with st.form("prediction_form"):
        st.subheader("ğŸ“Š Gezegen Ã–zellikleri")
        
        if input_mode == "ğŸ“ Basit Mod (Ana Ã–zellikler)":
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**ğŸŒ Gezegen Ã–zellikleri**")
                koi_period = st.number_input("YÃ¶rÃ¼nge Periyodu (gÃ¼n)", value=3.52, min_value=0.0, help="Gezegenin yÄ±ldÄ±zÄ±nÄ± Ã§evreleme sÃ¼resi")
                koi_prad = st.number_input("Gezegen YarÄ±Ã§apÄ± (DÃ¼nya)", value=1.89, min_value=0.0, help="DÃ¼nya yarÄ±Ã§apÄ± cinsinden")
                koi_teq = st.number_input("Denge SÄ±caklÄ±ÄŸÄ± (K)", value=1284.0, min_value=0.0, help="Kelvin cinsinden")
            
            with col2:
                st.markdown("**â­ YÄ±ldÄ±z Ã–zellikleri**")
                koi_steff = st.number_input("YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ± (K)", value=5455.0, min_value=0.0, help="Etkin sÄ±caklÄ±k")
                koi_srad = st.number_input("YÄ±ldÄ±z YarÄ±Ã§apÄ± (GÃ¼neÅŸ)", value=0.927, min_value=0.0, help="GÃ¼neÅŸ yarÄ±Ã§apÄ± cinsinden")
                koi_slogg = st.number_input("YÃ¼zey YerÃ§ekimi (log10)", value=4.467, min_value=0.0, help="cm/sÂ² cinsinden")
            
            with col3:
                st.markdown("**ğŸ”­ GÃ¶zlem Verileri**")
                koi_depth = st.number_input("GeÃ§iÅŸ DerinliÄŸi (ppm)", value=615.8, min_value=0.0, help="IÅŸÄ±k eÄŸrisindeki dÃ¼ÅŸÃ¼ÅŸ")
                koi_duration = st.number_input("GeÃ§iÅŸ SÃ¼resi (saat)", value=2.95, min_value=0.0, help="GeÃ§iÅŸin toplam sÃ¼resi")
                koi_model_snr = st.number_input("Sinyal-GÃ¼rÃ¼ltÃ¼ OranÄ±", value=35.8, min_value=0.0, help="Model SNR")
            
            # VarsayÄ±lan deÄŸerler
            features = {
                'koi_period': koi_period,
                'koi_depth': koi_depth,
                'koi_duration': koi_duration,
                'koi_ror': 0.0174,
                'koi_srho': 4.11,
                'koi_prad': koi_prad,
                'koi_teq': koi_teq,
                'koi_insol': 62.3,
                'koi_steff': koi_steff,
                'koi_slogg': koi_slogg,
                'koi_srad': koi_srad,
                'koi_impact': 0.146,
                'koi_model_snr': koi_model_snr,
                'koi_tce_plnt_num': 1,
                'koi_fpflag_nt': 0,
                'koi_fpflag_ss': 0,
                'koi_fpflag_co': 0,
                'koi_fpflag_ec': 0
            }
        
        else:  # GeliÅŸmiÅŸ Mod
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown("**ğŸŒ Gezegen**")
                koi_period = st.number_input("YÃ¶rÃ¼nge Periyodu (gÃ¼n)", value=3.52, min_value=0.0)
                koi_prad = st.number_input("Gezegen YarÄ±Ã§apÄ±", value=1.89, min_value=0.0)
                koi_teq = st.number_input("Denge SÄ±caklÄ±ÄŸÄ± (K)", value=1284.0, min_value=0.0)
                koi_insol = st.number_input("GÃ¼neÅŸ IÅŸÄ±nÄ±mÄ±", value=62.3, min_value=0.0)
                koi_ror = st.number_input("YarÄ±Ã§ap OranÄ±", value=0.0174, min_value=0.0)
            
            with col2:
                st.markdown("**â­ YÄ±ldÄ±z**")
                koi_steff = st.number_input("YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ± (K)", value=5455.0, min_value=0.0)
                koi_srad = st.number_input("YÄ±ldÄ±z YarÄ±Ã§apÄ±", value=0.927, min_value=0.0)
                koi_slogg = st.number_input("YÃ¼zey YerÃ§ekimi", value=4.467, min_value=0.0)
                koi_srho = st.number_input("YÄ±ldÄ±z YoÄŸunluÄŸu", value=4.11, min_value=0.0)
            
            with col3:
                st.markdown("**ğŸ”­ GÃ¶zlem**")
                koi_depth = st.number_input("GeÃ§iÅŸ DerinliÄŸi (ppm)", value=615.8, min_value=0.0)
                koi_duration = st.number_input("GeÃ§iÅŸ SÃ¼resi (saat)", value=2.95, min_value=0.0)
                koi_impact = st.number_input("Etki Parametresi", value=0.146, min_value=0.0)
                koi_model_snr = st.number_input("SNR", value=35.8, min_value=0.0)
                koi_tce_plnt_num = st.number_input("Gezegen No", value=1, min_value=1, step=1)
            
            with col4:
                st.markdown("**ğŸš© FP BayraklarÄ±**")
                koi_fpflag_nt = st.selectbox("Transit DÄ±ÅŸÄ±", [0, 1], index=0)
                koi_fpflag_ss = st.selectbox("YÄ±ldÄ±z TutulmasÄ±", [0, 1], index=0)
                koi_fpflag_co = st.selectbox("Merkez SapmasÄ±", [0, 1], index=0)
                koi_fpflag_ec = st.selectbox("Kontaminasyon", [0, 1], index=0)
            
            features = {
                'koi_period': koi_period,
                'koi_depth': koi_depth,
                'koi_duration': koi_duration,
                'koi_ror': koi_ror,
                'koi_srho': koi_srho,
                'koi_prad': koi_prad,
                'koi_teq': koi_teq,
                'koi_insol': koi_insol,
                'koi_steff': koi_steff,
                'koi_slogg': koi_slogg,
                'koi_srad': koi_srad,
                'koi_impact': koi_impact,
                'koi_model_snr': koi_model_snr,
                'koi_tce_plnt_num': int(koi_tce_plnt_num),
                'koi_fpflag_nt': koi_fpflag_nt,
                'koi_fpflag_ss': koi_fpflag_ss,
                'koi_fpflag_co': koi_fpflag_co,
                'koi_fpflag_ec': koi_fpflag_ec
            }
        
        # Tahmin butonu
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            predict_button = st.form_submit_button("ğŸš€ Tahmin Et", use_container_width=True)
    
    # Tahmin yap
    if predict_button:
        with st.spinner("ğŸ”® Tahmin yapÄ±lÄ±yor ve XAI analizi oluÅŸturuluyor..."):
            result = predict_exoplanet(
                features,
                model,
                scaler,
                feature_names,
                anomaly_detector=anomaly_detector,
            )
            
            # SonuÃ§ gÃ¶ster
            st.markdown("---")
            st.header("ğŸ“Š Tahmin SonuÃ§larÄ±")
            
            # Ana sonuÃ§
            if result['is_exoplanet']:
                st.markdown(
                    """
                    <div class="prediction-banner success">
                        ğŸ‰ Ã–tegezegen tespit edildi! Bu aday, model tarafÄ±ndan yÃ¼ksek gÃ¼venle doÄŸrulandÄ±.
                    </div>
                    """,
                    unsafe_allow_html=True,
                )
            else:
                st.markdown(
                    """
                    <div class="prediction-banner danger">
                        âŒ Ã–tegezegen olarak sÄ±nÄ±flandÄ±rÄ±lmadÄ±. Belirleyici metrikleri XAI sekmesinden inceleyin.
                    </div>
                    """,
                    unsafe_allow_html=True,
                )
            
            # Metrikler
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "Ã–tegezegen OlasÄ±lÄ±ÄŸÄ±",
                    f"{result['probability_exoplanet']*100:.2f}%",
                    delta=f"{(result['probability_exoplanet']-0.5)*100:.2f}%"
                )
            
            with col2:
                st.metric(
                    "Ã–tegezegen Olmama OlasÄ±lÄ±ÄŸÄ±",
                    f"{result['probability_not_exoplanet']*100:.2f}%"
                )
            
            with col3:
                st.metric(
                    "GÃ¼ven Skoru",
                    f"{result['confidence']*100:.2f}%"
                )
            
            with col4:
                confidence_emoji = "ğŸŸ¢" if result['confidence'] > 0.9 else "ğŸŸ¡" if result['confidence'] > 0.7 else "ğŸ”´"
                st.metric(
                    "GÃ¼venilirlik",
                    confidence_emoji,
                    "YÃ¼ksek" if result['confidence'] > 0.9 else "Orta" if result['confidence'] > 0.7 else "DÃ¼ÅŸÃ¼k"
                )

            novelty = result.get('novelty')
            if novelty is not None:
                novelty_cols = st.columns(2)
                novelty_score = novelty.get('novelty_score', 0.0)
                is_novel_candidate = novelty.get('is_novel_candidate', False)
                with novelty_cols[0]:
                    st.metric("Novelty Skoru", f"{novelty_score:.3f}")
                with novelty_cols[1]:
                    st.metric(
                        "Yeni Aday",
                        "ğŸš¨ EVET" if is_novel_candidate else "âœ… HAYIR",
                        help="IsolationForest tabanlÄ± anomalilik kontrolÃ¼"
                    )

                if is_novel_candidate:
                    st.warning(
                        "ğŸš¨ Model daÄŸÄ±lÄ±mÄ±nÄ±n dÄ±ÅŸÄ±nda kalan bir aday tespit edildi. Fiziksel doÄŸrulama ve ilave gÃ¶zlem Ã¶nerilir."
                    )
                else:
                    st.success(
                        "ğŸ›¡ï¸ Aday, eÄŸitim daÄŸÄ±lÄ±mÄ± ile uyumlu gÃ¶rÃ¼nÃ¼yor. Standart inceleme protokolÃ¼nÃ¼ uygulayabilirsiniz."
                    )
            
            # OlasÄ±lÄ±k grafiÄŸi
            st.subheader("ğŸ“Š OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ±")
            fig = go.Figure(data=[
                go.Bar(
                    x=['Ã–tegezegen DeÄŸil', 'Ã–tegezegen'],
                    y=[result['probability_not_exoplanet'], result['probability_exoplanet']],
                    marker_color=['#ff6a00', '#38ef7d'],
                    text=[f"{result['probability_not_exoplanet']*100:.2f}%", 
                          f"{result['probability_exoplanet']*100:.2f}%"],
                    textposition='auto',
                )
            ])
            fig.update_layout(
                title="SÄ±nÄ±f OlasÄ±lÄ±klarÄ±",
                yaxis_title="OlasÄ±lÄ±k",
                yaxis_range=[0, 1],
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # XAI AÃ§Ä±klamalarÄ±
            st.markdown("---")
            st.header("ğŸ§  XAI - AÃ§Ä±klanabilir AI Analizi")
            st.markdown("**'Model neden bu kararÄ± verdi?'** sorusuna detaylÄ± cevaplar")
            
            # Explainability Engine'i baÅŸlat
            try:
                xai_engine = ExplainabilityEngine(model, scaler, feature_names, explainer)
                full_explanation = xai_engine.generate_decision_explanation(
                    result['X_scaled'], 
                    result['X_original'],
                    result
                )
                
                # AnlatÄ±sal aÃ§Ä±klama
                st.markdown("### ğŸ“– Karar AÃ§Ä±klamasÄ±")
                
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.markdown("**ğŸ¤– AI Motoru AÃ§Ä±klamasÄ±**")
                    narrative = create_decision_narrative(full_explanation)
                    st.markdown(narrative)
                
                with col2:
                    st.markdown("**âœ¨ Gemini AI Yorumu**")
                    try:
                        with st.spinner("Gemini AI analiz ediyor..."):
                            gemini = GeminiExplainer(GEMINI_API_KEY)
                            gemini_explanation = gemini.generate_explanation(result, full_explanation)
                            
                            if gemini_explanation:
                                st.markdown(gemini_explanation)
                            else:
                                st.warning("Gemini AI yorumu oluÅŸturulamadÄ±.")
                    except Exception as gemini_error:
                        st.error(f"Gemini AI hatasÄ±: {gemini_error}")
                
            except Exception as e:
                st.warning(f"XAI Engine baÅŸlatÄ±lamadÄ±: {e}")
                full_explanation = None
            
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ“Š SHAP Analizi", 
                "ğŸ” Ã–zellik KatkÄ±larÄ±", 
                "ğŸ“ˆ Karar KurallarÄ±",
                "ğŸ¯ What-If Analizi",
                "ğŸ“‰ KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz"
            ])
            
            with tab1:
                st.subheader("SHAP (SHapley Additive exPlanations)")
                st.info("ğŸ¯ SHAP, her Ã¶zelliÄŸin tahmine olan katkÄ±sÄ±nÄ± gÃ¶sterir. Pozitif deÄŸerler Ã¶tegezegen olasÄ±lÄ±ÄŸÄ±nÄ± artÄ±rÄ±r, negatif deÄŸerler azaltÄ±r.")
                
                try:
                    # SHAP deÄŸerlerini hesapla
                    shap_values = get_shap_explanation(model, result['X_scaled'], explainer, feature_names)
                    
                    # Ä°nteraktif SHAP Waterfall Plot
                    st.markdown("**ğŸŒŠ Ä°nteraktif SHAP Waterfall Plot**")
                    st.caption("Her Ã¶zelliÄŸin tahmine olan katkÄ±sÄ±nÄ± gÃ¶sterir - Ã¼zerine gelin daha fazla bilgi iÃ§in")
                    
                    waterfall_fig = create_shap_waterfall_plotly(
                        shap_values[0],
                        explainer.expected_value,
                        result['X_scaled'][0],
                        feature_names,
                        max_display=10
                    )
                    st.plotly_chart(waterfall_fig, use_container_width=True)
                    
                    # SHAP Ã¶zet bilgileri
                    if full_explanation and full_explanation['shap_analysis']:
                        shap_info = full_explanation['shap_analysis']
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Toplam Pozitif Etki", f"+{shap_info['total_positive_impact']:.3f}")
                        with col2:
                            st.metric("Toplam Negatif Etki", f"{shap_info['total_negative_impact']:.3f}")
                        with col3:
                            net_impact = shap_info['total_positive_impact'] + shap_info['total_negative_impact']
                            st.metric("Net Etki", f"{net_impact:+.3f}")
                    
                    # En etkili Ã¶zellikler
                    st.markdown("**ğŸ† En Etkili 10 Ã–zellik**")
                    shap_df = pd.DataFrame({
                        'Ã–zellik': feature_names,
                        'DeÄŸer': result['X_scaled'][0],
                        'SHAP DeÄŸeri': shap_values[0],
                        'Etki YÃ¶nÃ¼': ['Pozitif â¬†ï¸' if v > 0 else 'Negatif â¬‡ï¸' if v < 0 else 'NÃ¶tr â¡ï¸' for v in shap_values[0]]
                    })
                    shap_df['Mutlak Etki'] = np.abs(shap_df['SHAP DeÄŸeri'])
                    shap_df = shap_df.sort_values('Mutlak Etki', ascending=False)
                    
                    st.dataframe(
                        shap_df[['Ã–zellik', 'DeÄŸer', 'SHAP DeÄŸeri', 'Etki YÃ¶nÃ¼']].head(10),
                        use_container_width=True
                    )
                    
                    # Matplotlib versiyonu (opsiyonel)
                    with st.expander("ğŸ“Š Klasik SHAP Waterfall Plot (Matplotlib)"):
                        fig, ax = plt.subplots(figsize=(10, 8))
                        shap.plots.waterfall(
                            shap.Explanation(
                                values=shap_values[0],
                                base_values=explainer.expected_value,
                                data=result['X_scaled'][0],
                                feature_names=feature_names
                            ),
                            show=False
                        )
                        st.pyplot(fig)
                        plt.close()
                    
                except Exception as e:
                    st.error(f"âŒ SHAP analizi hatasÄ±: {e}")
            
            with tab2:
                st.subheader("ğŸ” Ã–zellik KatkÄ± Analizi")
                st.info("ğŸ’¡ Her Ã¶zelliÄŸin modelin kararÄ±na olan katkÄ±sÄ±nÄ± detaylÄ± olarak gÃ¶sterir.")
                
                try:
                    if full_explanation and full_explanation['feature_contribution']:
                        contrib_data = full_explanation['feature_contribution']
                        contributions = contrib_data['contributions']
                        
                        # KatkÄ± grafiÄŸi
                        st.markdown("**ï¿½ AÄŸÄ±rlÄ±klÄ± Ã–zellik KatkÄ±larÄ±**")
                        
                        contrib_df = pd.DataFrame(contributions)
                        
                        fig = go.Figure(data=[
                            go.Bar(
                                x=contrib_df['weighted_contribution'].head(15),
                                y=contrib_df['feature'].head(15),
                                orientation='h',
                                marker=dict(
                                    color=contrib_df['weighted_contribution'].head(15),
                                    colorscale='RdYlGn',
                                    showscale=True,
                                    colorbar=dict(title="KatkÄ±")
                                ),
                                text=contrib_df['weighted_contribution'].head(15).apply(lambda x: f"{x:.3f}"),
                                textposition='auto',
                            )
                        ])
                        fig.update_layout(
                            title="En Etkili 15 Ã–zellik (AÄŸÄ±rlÄ±klÄ± KatkÄ±)",
                            xaxis_title="AÄŸÄ±rlÄ±klÄ± KatkÄ±",
                            yaxis_title="Ã–zellik",
                            height=600
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Model Ã¶nem derecesi vs SHAP karÅŸÄ±laÅŸtÄ±rmasÄ±
                        if full_explanation['shap_analysis']:
                            st.markdown("**âš–ï¸ Model Ã–nem Derecesi vs SHAP KarÅŸÄ±laÅŸtÄ±rmasÄ±**")
                            
                            shap_importance = np.abs(full_explanation['shap_analysis']['values'])
                            comp_fig = create_feature_importance_comparison(
                                model.feature_importances_,
                                shap_importance,
                                feature_names,
                                top_n=15
                            )
                            st.plotly_chart(comp_fig, use_container_width=True)
                        
                        # DetaylÄ± tablo
                        st.markdown("**ğŸ“‹ DetaylÄ± KatkÄ± Tablosu**")
                        display_df = contrib_df[['feature', 'value', 'importance', 'percentage', 'weighted_contribution']].head(15)
                        display_df.columns = ['Ã–zellik', 'DeÄŸer', 'Model Ã–nemi', 'YÃ¼zde (%)', 'AÄŸÄ±rlÄ±klÄ± KatkÄ±']
                        display_df['YÃ¼zde (%)'] = display_df['YÃ¼zde (%)'].apply(lambda x: f"{x:.2f}%")
                        st.dataframe(display_df, use_container_width=True)
                        
                    else:
                        st.warning("Ã–zellik katkÄ± analizi mevcut deÄŸil.")
                    
                except Exception as e:
                    st.error(f"âŒ Ã–zellik katkÄ± analizi hatasÄ±: {e}")
            
            with tab3:
                st.subheader("ï¿½ Karar KurallarÄ± ve EÅŸik DeÄŸerleri")
                st.info("ğŸ¯ Kritik Ã¶zelliklerin optimal aralÄ±klarda olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.")
                
                try:
                    if full_explanation and full_explanation['decision_rules']:
                        rules = full_explanation['decision_rules']
                        
                        # Karar yolu gÃ¶rselleÅŸtirmesi
                        st.markdown("**ğŸ›¤ï¸ Karar Yolu Analizi**")
                        decision_path_fig = create_decision_path_visualization(full_explanation)
                        if decision_path_fig:
                            st.plotly_chart(decision_path_fig, use_container_width=True)
                        
                        # Durum Ã¶zeti
                        optimal_count = sum(1 for r in rules if r['status'] == 'optimal')
                        acceptable_count = sum(1 for r in rules if r['status'] == 'acceptable')
                        out_of_range_count = sum(1 for r in rules if r['status'] == 'out_of_range')
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("âœ… Optimal", optimal_count)
                        with col2:
                            st.metric("âš ï¸ Kabul Edilebilir", acceptable_count)
                        with col3:
                            st.metric("âŒ AralÄ±k DÄ±ÅŸÄ±", out_of_range_count)
                        
                        # DetaylÄ± kurallar
                        st.markdown("**ï¿½ Kural DetaylarÄ±**")
                        
                        for rule in rules:
                            status_color = {
                                'optimal': 'green',
                                'acceptable': 'orange',
                                'out_of_range': 'red'
                            }[rule['status']]
                            
                            status_text = {
                                'optimal': 'âœ… Optimal',
                                'acceptable': 'âš ï¸ Kabul Edilebilir',
                                'out_of_range': 'âŒ AralÄ±k DÄ±ÅŸÄ±'
                            }[rule['status']]
                            
                            with st.expander(f"{status_text} - {rule['feature']}"):
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.metric("Mevcut DeÄŸer", f"{rule['value']:.2f}")
                                    st.markdown(f"**Optimal AralÄ±k:** {rule['optimal_range'][0]} - {rule['optimal_range'][1]}")
                                
                                with col2:
                                    st.markdown(f"**Minimum:** {rule['threshold_low']}")
                                    st.markdown(f"**Maksimum:** {rule['threshold_high']}")
                                    impact_emoji = "â¬†ï¸" if rule['impact'] == 'positive' else "â¬‡ï¸"
                                    st.markdown(f"**Etki:** {impact_emoji} {rule['impact'].title()}")
                    else:
                        st.warning("Karar kurallarÄ± mevcut deÄŸil.")
                        
                except Exception as e:
                    st.error(f"âŒ Karar kuralÄ± analizi hatasÄ±: {e}")
            
            with tab4:
                st.subheader("ğŸ¯ What-If Analizi")
                st.info("ğŸ”® Kritik Ã¶zelliklerdeki deÄŸiÅŸikliklerin tahmini nasÄ±l etkileyeceÄŸini simÃ¼le eder.")
                
                try:
                    if full_explanation and full_explanation['what_if_analysis']:
                        scenarios = full_explanation['what_if_analysis']
                        
                        st.markdown("**ğŸ§ª Senaryo SimÃ¼lasyonu**")
                        st.caption("Ã–zellikleri deÄŸiÅŸtirerek farklÄ± sonuÃ§larÄ± Ã¶ngÃ¶rÃ¼n")
                        
                        for scenario in scenarios:
                            with st.expander(f"ğŸ”¬ {scenario['feature']} SenaryolarÄ±"):
                                st.metric("Mevcut DeÄŸer", f"{scenario['original_value']:.3f}")
                                
                                st.markdown("**Alternatif Senaryolar:**")
                                
                                scenario_df = pd.DataFrame(scenario['scenarios'])
                                scenario_df.columns = ['DeÄŸiÅŸiklik', 'Yeni DeÄŸer']
                                scenario_df['Yeni DeÄŸer'] = scenario_df['Yeni DeÄŸer'].apply(lambda x: f"{x:.3f}")
                                st.dataframe(scenario_df, use_container_width=True)
                                
                                st.markdown("ğŸ’¡ **Not:** GerÃ§ek tahmin iÃ§in yukarÄ±daki deÄŸerleri kullanarak yeni bir tahmin yapabilirsiniz.")
                        
                        # Ä°nteraktif what-if
                        st.markdown("---")
                        st.markdown("**ğŸ® Ä°nteraktif What-If Simulator**")
                        
                        selected_feature = st.selectbox(
                            "DeÄŸiÅŸtirmek istediÄŸiniz Ã¶zelliÄŸi seÃ§in:",
                            options=[s['feature'] for s in scenarios]
                        )
                        
                        selected_scenario = next(s for s in scenarios if s['feature'] == selected_feature)
                        
                        new_value = st.slider(
                            f"{selected_feature} - Yeni DeÄŸer",
                            min_value=selected_scenario['original_value'] * 0.1,
                            max_value=selected_scenario['original_value'] * 2.0,
                            value=selected_scenario['original_value'],
                            step=selected_scenario['original_value'] * 0.05
                        )
                        
                        change_pct = ((new_value - selected_scenario['original_value']) / selected_scenario['original_value']) * 100
                        st.metric("DeÄŸiÅŸim YÃ¼zdesi", f"{change_pct:+.1f}%")
                        
                    else:
                        st.warning("What-if analizi mevcut deÄŸil.")
                        
                except Exception as e:
                    st.error(f"âŒ What-if analizi hatasÄ±: {e}")
            
            with tab5:
                st.subheader("ğŸ“‰ KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz")
                st.info("ğŸŒ GirdiÄŸiniz deÄŸerleri bilinen gezegenlerle karÅŸÄ±laÅŸtÄ±rÄ±n.")
                
                # Girilen Ã¶zellikler
                input_features = pd.DataFrame([features]).T
                input_features.columns = ['DeÄŸer']
                input_features['Ã–zellik'] = input_features.index
                input_features = input_features[['Ã–zellik', 'DeÄŸer']]
                
                st.markdown("**ğŸ“Š Girilen Ã–zellikler**")
                st.dataframe(input_features.head(10), use_container_width=True)
                
                # Referans karÅŸÄ±laÅŸtÄ±rmasÄ±
                st.markdown("**ğŸ”„ Bilinen Gezegenlerle KarÅŸÄ±laÅŸtÄ±rma**")
                
                comparison_data = {
                    'Ã–zellik': ['YÃ¶rÃ¼nge Periyodu (gÃ¼n)', 'Gezegen YarÄ±Ã§apÄ± (DÃ¼nya)', 'Denge SÄ±caklÄ±ÄŸÄ± (K)', 'YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ± (K)'],
                    'Sizin DeÄŸer': [
                        features.get('koi_period', 0),
                        features.get('koi_prad', 0),
                        features.get('koi_teq', 0),
                        features.get('koi_steff', 0)
                    ],
                    'DÃ¼nya': [365.25, 1.0, 255.0, 5778.0],
                    'Mars': [687.0, 0.532, 210.0, 5778.0],
                    'JÃ¼piter': [4333.0, 11.2, 110.0, 5778.0],
                    'NeptÃ¼n': [60182.0, 3.88, 55.0, 5778.0]
                }
                
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df, use_container_width=True)
                
                # GÃ¶rsel karÅŸÄ±laÅŸtÄ±rma
                st.markdown("**ğŸ“Š GÃ¶rsel KarÅŸÄ±laÅŸtÄ±rma**")
                
                fig = go.Figure()
                
                for planet in ['DÃ¼nya', 'Mars', 'JÃ¼piter', 'NeptÃ¼n']:
                    fig.add_trace(go.Bar(
                        name=planet,
                        x=comparison_data['Ã–zellik'][:3],  # Ä°lk 3 Ã¶zellik
                        y=[comparison_df[comparison_df['Ã–zellik'] == feat][planet].values[0] 
                           for feat in comparison_data['Ã–zellik'][:3]],
                    ))
                
                fig.add_trace(go.Bar(
                    name='Sizin DeÄŸer',
                    x=comparison_data['Ã–zellik'][:3],
                    y=comparison_data['Sizin DeÄŸer'][:3],
                    marker_color='red'
                ))
                
                fig.update_layout(
                    title="Gezegen Ã–zelliklerinin KarÅŸÄ±laÅŸtÄ±rmasÄ±",
                    xaxis_title="Ã–zellik",
                    yaxis_title="DeÄŸer",
                    barmode='group',
                    height=500
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # GÃ¼ven faktÃ¶rleri
                if full_explanation and full_explanation['confidence_factors']:
                    st.markdown("**ğŸ¯ GÃ¼venilirlik FaktÃ¶rleri**")
                    
                    conf_factors = full_explanation['confidence_factors']
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("GÃ¼ven Seviyesi", f"{conf_factors['confidence_level']*100:.1f}%")
                    with col2:
                        st.metric("OlasÄ±lÄ±k MarjÄ±", f"{conf_factors['probability_margin']:.3f}")
                    
                    if conf_factors['factors']:
                        for factor in conf_factors['factors']:
                            impact_emoji = "âœ…" if factor['impact'] == 'positive' else "âš ï¸"
                            st.markdown(f"{impact_emoji} **{factor['factor']}:** {factor['description']}")


def show_3d_star_system_page():
    """3B etkileÅŸimli yÄ±ldÄ±z sistemi gÃ¶rselleÅŸtirmesi"""
    st.header("ğŸŒŒ 3B YÄ±ldÄ±z Sistemi GÃ¶rselleÅŸtirmesi")
    st.markdown(
        "Kepler sistemlerini Ã¼Ã§ boyutlu uzayda keÅŸfedin. Gezegenlerin yÄ±ldÄ±zlarÄ±na gÃ¶re konumlarÄ±nÄ±, "
        "yÃ¶rÃ¼ngelerini ve fiziksel Ã¶zelliklerini interaktif olarak inceleyin."
    )

    # Veri yÃ¼kleme
    try:
        default_path = Path('cumulative_2025.10.04_09.55.40.csv')
        if default_path.exists():
            df_raw = pd.read_csv(default_path, comment='#')
        else:
            df_raw = load_default_reference_dataframe()
    except Exception as exc:
        st.error(f"Veri yÃ¼klenirken hata oluÅŸtu: {exc}")
        return

    # Temel filtreleme - sadece CONFIRMED gezegenleri al
    df = df_raw[df_raw['koi_disposition'] == 'CONFIRMED'].copy()
    
    # Minimum gerekli sÃ¼tunlar (yÃ¶rÃ¼nge periyodu ve gezegen yarÄ±Ã§apÄ± zorunlu)
    minimal_required = ['koi_period', 'koi_prad']
    optional_cols = ['koi_teq', 'koi_srad', 'koi_steff']
    
    # SayÄ±sal dÃ¶nÃ¼ÅŸÃ¼m
    for col in minimal_required + optional_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # Sadece zorunlu sÃ¼tunlarda NaN olanlarÄ± Ã§Ä±kar
    df = df.dropna(subset=minimal_required)
    
    # Opsiyonel sÃ¼tunlar iÃ§in varsayÄ±lan deÄŸerler
    if 'koi_teq' not in df.columns or df['koi_teq'].isna().all():
        df['koi_teq'] = 300  # VarsayÄ±lan sÄ±caklÄ±k
    else:
        df['koi_teq'] = df['koi_teq'].fillna(df['koi_teq'].median())
    
    if 'koi_srad' not in df.columns or df['koi_srad'].isna().all():
        df['koi_srad'] = 1.0  # VarsayÄ±lan yÄ±ldÄ±z yarÄ±Ã§apÄ± (GÃ¼neÅŸ yarÄ±Ã§apÄ±)
    else:
        df['koi_srad'] = df['koi_srad'].fillna(df['koi_srad'].median())
    
    if 'koi_steff' not in df.columns or df['koi_steff'].isna().all():
        df['koi_steff'] = 5778  # VarsayÄ±lan yÄ±ldÄ±z sÄ±caklÄ±ÄŸÄ± (GÃ¼neÅŸ sÄ±caklÄ±ÄŸÄ±)
    else:
        df['koi_steff'] = df['koi_steff'].fillna(df['koi_steff'].median())

    if df.empty:
        st.warning("GÃ¶rselleÅŸtirme iÃ§in yeterli CONFIRMED gezegen verisi bulunamadÄ±.")
        return
    
    # Pozitif deÄŸer kontrolÃ¼
    df = df[(df['koi_period'] > 0) & (df['koi_prad'] > 0)]
    
    if df.empty:
        st.warning("GeÃ§erli yÃ¶rÃ¼nge verisi bulunamadÄ±.")
        return

    st.info(f"ğŸ“Š GÃ¶rselleÅŸtirilen gezegen sayÄ±sÄ±: {len(df):,}")

    # Kontrol paneli
    st.markdown("### âš™ï¸ GÃ¶rselleÅŸtirme Kontrolleri")
    col_ctrl1, col_ctrl2, col_ctrl3 = st.columns(3)

    with col_ctrl1:
        color_by = st.selectbox(
            "Renklendirme",
            ["koi_teq", "koi_prad", "koi_steff", "koi_period"],
            format_func=lambda x: {
                "koi_teq": "Denge SÄ±caklÄ±ÄŸÄ±",
                "koi_prad": "Gezegen YarÄ±Ã§apÄ±",
                "koi_steff": "YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ±",
                "koi_period": "YÃ¶rÃ¼nge Periyodu"
            }[x]
        )

    with col_ctrl2:
        size_by = st.selectbox(
            "Nokta Boyutu",
            ["koi_prad", "koi_period", "koi_teq"],
            format_func=lambda x: {
                "koi_prad": "Gezegen YarÄ±Ã§apÄ±",
                "koi_period": "YÃ¶rÃ¼nge Periyodu",
                "koi_teq": "Denge SÄ±caklÄ±ÄŸÄ±"
            }[x]
        )

    with col_ctrl3:
        max_points = st.slider("Maksimum nokta sayÄ±sÄ±", 50, 500, 200, 50)

    # Veriyi sÄ±nÄ±rla
    df_viz = df.head(max_points).copy()

    # 3B koordinatlarÄ± hesapla (yÃ¶rÃ¼nge yaklaÅŸÄ±mÄ±)
    # BasitleÅŸtirilmiÅŸ model: yÃ¶rÃ¼nge periyodu ve gezegen bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re konumlandÄ±rma
    df_viz['orbit_radius'] = np.cbrt(df_viz['koi_period'])  # Kepler's 3rd law approximation
    df_viz['theta'] = np.random.uniform(0, 2*np.pi, len(df_viz))
    df_viz['phi'] = np.random.uniform(0, np.pi, len(df_viz))
    
    df_viz['x'] = df_viz['orbit_radius'] * np.sin(df_viz['phi']) * np.cos(df_viz['theta'])
    df_viz['y'] = df_viz['orbit_radius'] * np.sin(df_viz['phi']) * np.sin(df_viz['theta'])
    df_viz['z'] = df_viz['orbit_radius'] * np.cos(df_viz['phi'])

    # YÄ±ldÄ±z skalasÄ± (normalize)
    df_viz['star_size'] = (df_viz['koi_srad'] / df_viz['koi_srad'].mean()) * 5
    df_viz['planet_size'] = (df_viz[size_by] / df_viz[size_by].max()) * 15 + 5

    st.markdown("### ğŸŒŒ Ä°nteraktif 3B GÃ¶rÃ¼nÃ¼m")
    
    # Ana 3B scatter plot
    fig = go.Figure()

    # Merkezi yÄ±ldÄ±zlarÄ± temsil eden noktalar (daha bÃ¼yÃ¼k)
    fig.add_trace(go.Scatter3d(
        x=[0],
        y=[0],
        z=[0],
        mode='markers',
        marker=dict(
            size=25,
            color='yellow',
            symbol='diamond',
            line=dict(color='orange', width=2)
        ),
        name='Merkez YÄ±ldÄ±z (ref)',
        hovertemplate='<b>Merkez YÄ±ldÄ±z</b><extra></extra>'
    ))

    # Gezegenleri gÃ¶ster
    hover_template = (
        '<b>Gezegen</b><br>'
        'YÃ¶rÃ¼nge Periyodu: %{customdata[0]:.2f} gÃ¼n<br>'
        'YarÄ±Ã§ap: %{customdata[1]:.2f} RâŠ•<br>'
        'SÄ±caklÄ±k: %{customdata[2]:.0f} K<br>'
        'YÄ±ldÄ±z YarÄ±Ã§apÄ±: %{customdata[3]:.2f} Râ˜‰<br>'
        'YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ±: %{customdata[4]:.0f} K'
        '<extra></extra>'
    )

    fig.add_trace(go.Scatter3d(
        x=df_viz['x'],
        y=df_viz['y'],
        z=df_viz['z'],
        mode='markers',
        marker=dict(
            size=df_viz['planet_size'],
            color=df_viz[color_by],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(
                title=color_by.replace('koi_', '').replace('_', ' ').title(),
                x=1.1
            ),
            line=dict(color='white', width=0.5)
        ),
        customdata=np.column_stack((
            df_viz['koi_period'],
            df_viz['koi_prad'],
            df_viz['koi_teq'],
            df_viz['koi_srad'],
            df_viz['koi_steff']
        )),
        hovertemplate=hover_template,
        name='Ã–tegezegen'
    ))

    # Layout
    fig.update_layout(
        scene=dict(
            xaxis=dict(
                title='X (YÃ¶rÃ¼nge Ekseni)',
                backgroundcolor="rgba(0, 0, 0, 0.1)",
                gridcolor="gray",
                showbackground=True,
            ),
            yaxis=dict(
                title='Y (YÃ¶rÃ¼nge Ekseni)',
                backgroundcolor="rgba(0, 0, 0, 0.1)",
                gridcolor="gray",
                showbackground=True,
            ),
            zaxis=dict(
                title='Z (YÃ¶rÃ¼nge Ekseni)',
                backgroundcolor="rgba(0, 0, 0, 0.1)",
                gridcolor="gray",
                showbackground=True,
            ),
            camera=dict(
                eye=dict(x=1.5, y=1.5, z=1.5),
                center=dict(x=0, y=0, z=0),
                up=dict(x=0, y=0, z=1)
            ),
            aspectmode='cube'
        ),
        title={
            'text': '3B Kepler YÄ±ldÄ±z Sistemi HaritasÄ±',
            'x': 0.5,
            'xanchor': 'center'
        },
        showlegend=True,
        height=700,
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)'
    )

    st.plotly_chart(fig, use_container_width=True)

    # Ä°statistikler
    st.markdown("### ğŸ“Š Sistem Ä°statistikleri")
    stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)

    with stat_col1:
        st.metric("Ortalama YÃ¶rÃ¼nge Periyodu", f"{df_viz['koi_period'].mean():.1f} gÃ¼n")
    with stat_col2:
        st.metric("Ortalama Gezegen YarÄ±Ã§apÄ±", f"{df_viz['koi_prad'].mean():.2f} RâŠ•")
    with stat_col3:
        st.metric("Ortalama SÄ±caklÄ±k", f"{df_viz['koi_teq'].mean():.0f} K")
    with stat_col4:
        st.metric("Ortalama YÄ±ldÄ±z YarÄ±Ã§apÄ±", f"{df_viz['koi_srad'].mean():.2f} Râ˜‰")

    # DetaylÄ± veri tablosu
    with st.expander("ğŸ“‹ DetaylÄ± Veri Tablosu"):
        display_columns = ['koi_period', 'koi_prad', 'koi_teq', 'koi_srad', 'koi_steff', 'orbit_radius']
        st.dataframe(
            df_viz[display_columns].head(50),
            use_container_width=True
        )

    # AÃ§Ä±klama
    st.markdown("""
    ---
    ### ğŸ“– GÃ¶rselleÅŸtirme HakkÄ±nda
    
    Bu 3B gÃ¶rselleÅŸtirme, Kepler kataloÄŸundaki onaylanmÄ±ÅŸ Ã¶tegezegenlerin yÄ±ldÄ±zlarÄ±na gÃ¶re 
    yaklaÅŸÄ±k konumlarÄ±nÄ± gÃ¶sterir. Koordinatlar, Kepler'in 3. yasasÄ±na dayalÄ± basitleÅŸtirilmiÅŸ 
    bir model kullanÄ±larak hesaplanmÄ±ÅŸtÄ±r.
    
    - **Merkez nokta**: Referans yÄ±ldÄ±zÄ± temsil eder
    - **Renkli noktalar**: Her biri onaylanmÄ±ÅŸ bir Ã¶tegezegeni temsil eder
    - **Nokta boyutu**: SeÃ§ilen fiziksel Ã¶zelliÄŸe gÃ¶re Ã¶lÃ§eklenir
    - **Renk**: SeÃ§ilen fiziksel parametreyi gÃ¶sterir
    
    ğŸ¯ **EtkileÅŸim Ä°puÃ§larÄ±:**
    - Fareyle sÃ¼rÃ¼kleyerek gÃ¶rÃ¼nÃ¼mÃ¼ dÃ¶ndÃ¼rÃ¼n
    - Tekerlek ile yakÄ±nlaÅŸtÄ±rÄ±n/uzaklaÅŸtÄ±rÄ±n
    - Noktalara tÄ±klayarak detaylÄ± bilgi gÃ¶rÃ¼n
    """)


def show_live_data_page(model, scaler, feature_names, anomaly_detector):
    """NASA canlÄ± kataloÄŸunu gÃ¶rÃ¼ntÃ¼ler ve hibrit analiz uygular."""
    st.header("ğŸ›°ï¸ NASA CanlÄ± Exoplanet AkÄ±ÅŸÄ±")
    st.markdown(
        "GerÃ§ek zamanlÄ± **Kepler** NASA Exoplanet Archive kataloÄŸunu Ã§ekip hibrit fiziksel filtreler, "
        "anomali tespiti ve 3B gÃ¶rselleÅŸtirme ile deÄŸerlendirin."
    )

    mission_options = {
        "Kepler (Primary Mission)": "kepler",
    }

    col_sel1, col_sel2, col_sel3 = st.columns([1.4, 1, 1])
    mission_label = list(mission_options.keys())[0]
    with col_sel1:
        st.markdown(f"**GÃ¶rev:** {mission_label}")
    with col_sel2:
        limit = st.slider("KayÄ±t limiti", min_value=100, max_value=5000, value=500, step=100)
    with col_sel3:
        force_refresh = st.checkbox(
            "Ã–nbelleÄŸi yenile",
            value=False,
            help="Etkin olduÄŸunda NASA API'dan taze veri Ã§ekilir.",
        )

    mission_code = mission_options[mission_label]

    try:
        with st.spinner(f"{mission_label} kataloÄŸu getiriliyor..."):
            live_df = fetch_live_catalog(mission_code, limit, force_refresh)
    except Exception as exc:
        st.error(f"NASA verisi alÄ±namadÄ±: {exc}")
        return

    if live_df.empty:
        st.warning("Belirtilen kriterlerle eÅŸleÅŸen kayÄ±t bulunamadÄ±.")
        return

    scoring = score_catalog(live_df, model, scaler, list(feature_names), anomaly_detector)
    scored_df = scoring["scored"]

    st.caption(
        "Veriler NASA Exoplanet Archive TAP API Ã¼zerinden alÄ±nÄ±r ve yerelde 15 dakika boyunca cache'lenir."
    )

    total_records = len(scored_df)
    dispositions = (
        scored_df["koi_disposition"].str.upper()
        if "koi_disposition" in scored_df.columns
        else pd.Series(["UNKNOWN"] * total_records)
    )
    confirmed_count = int((dispositions == "CONFIRMED").sum()) if not dispositions.empty else 0
    candidate_count = int((dispositions == "CANDIDATE").sum()) if not dispositions.empty else 0
    novel_count = int(scored_df.get("is_novel_candidate", pd.Series(dtype=bool)).sum())
    high_conf = int((scored_df["model_probability"] >= 0.9).sum())

    metric_cols = st.columns(4)
    with metric_cols[0]:
        st.metric("KayÄ±t SayÄ±sÄ±", f"{total_records:,}")
    with metric_cols[1]:
        st.metric("CONFIRMED", f"{confirmed_count:,}")
    with metric_cols[2]:
        st.metric("Adaylar", f"{candidate_count:,}")
    with metric_cols[3]:
        st.metric("YÃ¼ksek GÃ¼ven (â‰¥0.9)", f"{high_conf:,}")

    if anomaly_detector is not None:
        st.info(
            f"ğŸ§­ {novel_count} kayÄ±t, daÄŸÄ±lÄ±m dÄ±ÅŸÄ± potansiyel yeni aday olarak iÅŸaretlendi."
            if novel_count
            else "ğŸ›¡ï¸ Anomali modeli ÅŸu anda yeni aday saptamadÄ±."
        )

    filtered_df = scored_df.copy()
    with st.expander("ğŸ”¬ Hibrit fizik filtreleri"):
        if "koi_teq" in filtered_df.columns:
            teq_min = float(filtered_df["koi_teq"].min())
            teq_max = float(filtered_df["koi_teq"].max())
            if teq_min < teq_max:
                teq_range = st.slider(
                    "Denge sÄ±caklÄ±ÄŸÄ± (K)",
                    min_value=float(round(teq_min, 2)),
                    max_value=float(round(teq_max, 2)),
                    value=(float(round(teq_min, 2)), float(round(teq_max, 2))),
                    key="live_teq_range",
                )
                filtered_df = filtered_df[filtered_df["koi_teq"].between(*teq_range)]

        if "koi_period" in filtered_df.columns:
            per_min = float(filtered_df["koi_period"].min())
            per_max = float(filtered_df["koi_period"].max())
            if per_min < per_max:
                period_range = st.slider(
                    "YÃ¶rÃ¼nge periyodu (gÃ¼n)",
                    min_value=float(round(per_min, 2)),
                    max_value=float(round(per_max, 2)),
                    value=(float(round(per_min, 2)), float(round(per_max, 2))),
                    key="live_period_range",
                )
                filtered_df = filtered_df[filtered_df["koi_period"].between(*period_range)]

        if "koi_prad" in filtered_df.columns:
            prad_min = float(filtered_df["koi_prad"].min())
            prad_max = float(filtered_df["koi_prad"].max())
            if prad_min < prad_max:
                prad_range = st.slider(
                    "Gezegen yarÄ±Ã§apÄ± (DÃ¼nya)",
                    min_value=float(round(prad_min, 2)),
                    max_value=float(round(prad_max, 2)),
                    value=(float(round(prad_min, 2)), float(round(prad_max, 2))),
                    key="live_prad_range",
                )
                filtered_df = filtered_df[filtered_df["koi_prad"].between(*prad_range)]

        only_novel = st.checkbox(
            "YalnÄ±zca yeni adaylarÄ± listele",
            value=False,
            key="live_novel_only",
        )

    display_df = (
        filtered_df[filtered_df["is_novel_candidate"]]
        if only_novel and "is_novel_candidate" in filtered_df
        else filtered_df
    )

    st.markdown(
        f"**GÃ¶rÃ¼ntÃ¼lenen kayÄ±t sayÄ±sÄ±:** {len(display_df):,} / {total_records:,}"
    )

    # DEBUG: SÃ¼tun ve veri durumunu kontrol et
    available_cols = list(display_df.columns)
    
    # 3D gÃ¶rselleÅŸtirme iÃ§in minimum gereksinimler (sadece period ve prad zorunlu)
    minimal_plot_cols = ["koi_period", "koi_prad"]
    optional_plot_col = "koi_teq"
    
    # SÃ¼tunlarÄ± kontrol et
    missing_cols = [col for col in minimal_plot_cols if col not in available_cols]
    
    if missing_cols:
        st.warning(f"âš ï¸ Gerekli sÃ¼tunlar eksik: {', '.join(missing_cols)}")
        st.info(f"ğŸ“‹ Mevcut sÃ¼tunlar: {', '.join([c for c in available_cols if 'koi' in c.lower()][:10])}")
    elif display_df.empty:
        st.warning("ğŸ“­ GÃ¶rÃ¼ntÃ¼lenecek kayÄ±t yok (filtreler Ã§ok kÄ±sÄ±tlayÄ±cÄ± olabilir)")
    elif all(col in display_df.columns for col in minimal_plot_cols):
        # Sadece zorunlu sÃ¼tunlarda NaN olanlarÄ± Ã§Ä±kar
        plot_df = display_df.dropna(subset=minimal_plot_cols).copy()
        
        # SayÄ±sal dÃ¶nÃ¼ÅŸÃ¼m
        for col in minimal_plot_cols + [optional_plot_col]:
            if col in plot_df.columns:
                plot_df[col] = pd.to_numeric(plot_df[col], errors="coerce")
        
        # Zorunlu sÃ¼tunlarÄ± tekrar kontrol et
        plot_df = plot_df.dropna(subset=minimal_plot_cols)
        
        # Opsiyonel koi_teq iÃ§in varsayÄ±lan deÄŸer
        if optional_plot_col in plot_df.columns:
            if plot_df[optional_plot_col].isna().all():
                plot_df[optional_plot_col] = 300  # VarsayÄ±lan sÄ±caklÄ±k
            else:
                plot_df[optional_plot_col] = plot_df[optional_plot_col].fillna(
                    plot_df[optional_plot_col].median()
                )
        else:
            plot_df[optional_plot_col] = 300
        
        if plot_df.empty:
            st.info("3B gÃ¶rselleÅŸtirme iÃ§in yeterli Ã¶lÃ§Ã¼m mevcut deÄŸil (minimum: koi_period ve koi_prad gerekli).")
        else:
            hover_candidates = ["koi_disposition", "novelty_score", "source_mission"]
            hover_map = {
                col: True
                for col in hover_candidates
                if col in plot_df.columns
            }
            hover_map["model_probability"] = ":.2f"

            fig = px.scatter_3d(
                plot_df,
                x="koi_period",
                y="koi_prad",
                z="koi_teq",
                color="model_probability",
                color_continuous_scale="Turbo",
                hover_data=hover_map,
                title="3B GÃ¶rev keÅŸif haritasÄ±",
            )

            if "is_novel_candidate" in plot_df.columns and plot_df["is_novel_candidate"].any():
                novel_points = plot_df[plot_df["is_novel_candidate"]]
                fig.add_trace(
                    go.Scatter3d(
                        x=novel_points["koi_period"],
                        y=novel_points["koi_prad"],
                        z=novel_points["koi_teq"],
                        mode="markers",
                        marker=dict(color="#ff4d4f", size=6, symbol="diamond"),
                        name="Yeni aday",
                    )
                )

            fig.update_scenes(
                xaxis_title="Periyot (gÃ¼n)", yaxis_title="YarÄ±Ã§ap (DÃ¼nya)", zaxis_title="Teq (K)"
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("3B gÃ¶rselleÅŸtirme iÃ§in yeterli fiziksel Ã¶zellik bulunamadÄ±.")

    # Model Tahmin Ä°statistikleri
    st.markdown("### ğŸ¤– Model DeÄŸerlendirme SonuÃ§larÄ±")
    
    if "model_probability" in display_df.columns and "model_prediction" in display_df.columns:
        # FarklÄ± gÃ¼ven seviyelerine gÃ¶re tahminler
        high_confidence = display_df[display_df["model_probability"] >= 0.9]
        medium_confidence = display_df[display_df["model_probability"].between(0.7, 0.9)]
        low_confidence = display_df[display_df["model_probability"] < 0.7]
        
        # Model tahminlerine gÃ¶re Ã¶tegezegen sayÄ±larÄ±
        predicted_exoplanets = display_df[display_df["model_prediction"] == "CONFIRMED"]
        predicted_non_exoplanets = display_df[display_df["model_prediction"] == "OTHER"]
        
        # Metrikler
        metric_cols = st.columns(5)
        with metric_cols[0]:
            st.metric(
                "ğŸª Ã–tegezegen Tahmini", 
                f"{len(predicted_exoplanets):,}",
                help="Model tarafÄ±ndan CONFIRMED olarak tahmin edilen objeler"
            )
        with metric_cols[1]:
            st.metric(
                "âŒ Ã–tegezegen DeÄŸil", 
                f"{len(predicted_non_exoplanets):,}",
                help="Model tarafÄ±ndan OTHER olarak sÄ±nÄ±flandÄ±rÄ±lan objeler"
            )
        with metric_cols[2]:
            st.metric(
                "ğŸ¯ YÃ¼ksek GÃ¼ven (â‰¥90%)", 
                f"{len(high_confidence):,}",
                help="Model %90 veya daha yÃ¼ksek gÃ¼venle tahmin etti"
            )
        with metric_cols[3]:
            st.metric(
                "âš¡ Orta GÃ¼ven (70-90%)", 
                f"{len(medium_confidence):,}",
                help="Model %70-90 arasÄ± gÃ¼venle tahmin etti"
            )
        with metric_cols[4]:
            st.metric(
                "âš ï¸ DÃ¼ÅŸÃ¼k GÃ¼ven (<70%)", 
                f"{len(low_confidence):,}",
                help="Model %70'in altÄ±nda gÃ¼venle tahmin etti"
            )
        
        # NASA etiketleri ile karÅŸÄ±laÅŸtÄ±rma
        if "koi_disposition" in display_df.columns:
            st.markdown("#### ğŸ“Š Model vs NASA KarÅŸÄ±laÅŸtÄ±rmasÄ±")
            
            comparison_df = display_df.copy()
            comparison_df["nasa_label"] = comparison_df["koi_disposition"].str.upper()
            
            # DoÄŸruluk metrikleri
            nasa_confirmed = comparison_df[comparison_df["nasa_label"] == "CONFIRMED"]
            nasa_candidate = comparison_df[comparison_df["nasa_label"] == "CANDIDATE"]
            nasa_false_positive = comparison_df[comparison_df["nasa_label"] == "FALSE POSITIVE"]
            
            # Model'in NASA CONFIRMED'larÄ± ne kadar yakaladÄ±ÄŸÄ±
            if len(nasa_confirmed) > 0:
                model_agrees_confirmed = nasa_confirmed[nasa_confirmed["model_prediction"] == "CONFIRMED"]
                agreement_rate = len(model_agrees_confirmed) / len(nasa_confirmed) * 100
                
                col_comp1, col_comp2 = st.columns(2)
                with col_comp1:
                    st.info(f"âœ… **NASA CONFIRMED:** {len(nasa_confirmed):,} obje")
                    st.success(f"ğŸ¯ Model Uyumu: %{agreement_rate:.1f} ({len(model_agrees_confirmed):,}/{len(nasa_confirmed):,})")
                
                with col_comp2:
                    if len(nasa_candidate) > 0:
                        model_promotes_candidate = nasa_candidate[nasa_candidate["model_prediction"] == "CONFIRMED"]
                        st.info(f"ğŸ” **NASA CANDIDATE:** {len(nasa_candidate):,} obje")
                        st.warning(f"â¬†ï¸ Model Terfi: {len(model_promotes_candidate):,} objeyi CONFIRMED olarak deÄŸerlendirdi")
        
        # En yÃ¼ksek gÃ¼venle tahmin edilen Ã¶tegezegenleri gÃ¶ster
        if len(predicted_exoplanets) > 0:
            st.markdown("#### ğŸŒŸ En GÃ¼venilir Ã–tegezegen Tahminleri (Top 10)")
            
            top_exoplanets = predicted_exoplanets.nlargest(10, "model_probability")
            
            display_cols = [
                col for col in [
                    "kepoi_name", "koi_disposition", "koi_period", "koi_prad", 
                    "koi_teq", "model_probability", "novelty_score"
                ] if col in top_exoplanets.columns
            ]
            
            # Renklendirme iÃ§in stil
            def highlight_probability(val):
                if pd.isna(val):
                    return ''
                if isinstance(val, (int, float)):
                    if val >= 0.95:
                        return 'background-color: #d4edda; font-weight: bold'
                    elif val >= 0.90:
                        return 'background-color: #d1ecf1'
                return ''
            
            styled_df = top_exoplanets[display_cols].style.applymap(
                highlight_probability, 
                subset=['model_probability'] if 'model_probability' in display_cols else []
            )
            
            st.dataframe(styled_df, use_container_width=True)
    else:
        st.warning("Model tahmin sonuÃ§larÄ± bulunamadÄ±.")

    st.markdown("### ğŸ“‹ GÃ¶rev tablosu")
    columns_to_show = [
        col
        for col in [
            "koi_name",
            "koi_disposition",
            "koi_period",
            "koi_prad",
            "koi_teq",
            "model_probability",
            "novelty_score",
            "is_novel_candidate",
        ]
        if col in display_df.columns
    ]

    st.markdown("### ğŸ“‹ TÃ¼m DeÄŸerlendirilen Objeler")
    st.caption("Model tarafÄ±ndan skorlanan tÃ¼m objeler (ilk 100 kayÄ±t)")
    st.dataframe(display_df[columns_to_show].head(100), use_container_width=True)

    csv_buffer = BytesIO()
    display_df.to_csv(csv_buffer, index=False)
    csv_buffer.seek(0)
    st.download_button(
        label="ğŸ“¥ Ä°ncelenen veriyi indir",
        data=csv_buffer,
        file_name=f"nasa_live_catalog_{mission_code}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
    )


def show_batch_analysis_page(model, scaler, feature_names, anomaly_detector):
    """Toplu analiz sayfasÄ±"""
    st.header("ğŸ“Š Toplu Ã–tegezegen Analizi")
    st.markdown("CSV dosyasÄ± yÃ¼kleyerek birden fazla gezegen adayÄ±nÄ± analiz edin.")
    
    # GÃ¼venlik bilgisi
    with st.expander("ğŸ”’ Veri GÃ¼venliÄŸi ve Gizlilik"):
        st.markdown("""
        **Dosya Gereksinimleri:**
        - âœ… Sadece **CSV** formatÄ± kabul edilir
        - âœ… Maksimum dosya boyutu: **100 MB**
        
        **Veri AnonimleÅŸtirme:**
        - ğŸ” Hassas bilgiler (isimler, ID'ler, koordinatlar) otomatik olarak anonimleÅŸtirilir
        - ğŸ” AnonimleÅŸtirme isteÄŸe baÄŸlÄ±dÄ±r ve kontrol edilebilir
        - ğŸ” Orijinal verileriniz deÄŸiÅŸtirilmez, sadece analiz iÃ§in kopyasÄ± kullanÄ±lÄ±r
        """)
    
    # AnonimleÅŸtirme seÃ§eneÄŸi
    col1, col2 = st.columns([3, 1])
    with col1:
        uploaded_file = st.file_uploader("ğŸ“ CSV DosyasÄ± YÃ¼kleyin", type=['csv'])
    with col2:
        anonymize_data = st.checkbox("ğŸ”’ Veriyi AnonimleÅŸtir", value=True, 
                                     help="Hassas bilgileri otomatik olarak anonimleÅŸtirir")
    
    if uploaded_file is not None:
        # Dosya doÄŸrulama
        is_valid, validation_message = validate_csv_file(uploaded_file)
        
        if not is_valid:
            st.error(validation_message)
            st.warning("âš ï¸ LÃ¼tfen geÃ§erli bir CSV dosyasÄ± yÃ¼kleyin.")
            st.stop()
        
        try:
            # CSV'yi oku
            df = pd.read_csv(uploaded_file)
            
            st.success(f"âœ… {len(df)} satÄ±r, {len(df.columns)} sÃ¼tun baÅŸarÄ±yla yÃ¼klendi!")
            
            # Veri anonimleÅŸtirme
            anonymization_report = None
            if anonymize_data:
                with st.spinner("ğŸ” Veriler anonimleÅŸtiriliyor..."):
                    df, anonymization_report = anonymize_sensitive_columns(df)
                
                if anonymization_report['anonymized_columns']:
                    st.info(f"ğŸ”’ **{len(anonymization_report['anonymized_columns'])}** sÃ¼tun anonimleÅŸtirildi: "
                           f"{', '.join([f'`{col}`' for col in anonymization_report['anonymized_columns']])}")
                else:
                    st.info("â„¹ï¸ AnonimleÅŸtirilecek hassas sÃ¼tun bulunamadÄ±.")
            
            # Veri Ã¶nizleme
            with st.expander("ğŸ‘€ Veri Ã–nizleme"):
                st.dataframe(df.head(10), use_container_width=True)
                
                if anonymization_report and anonymization_report['anonymized_columns']:
                    st.markdown("**ğŸ” AnonimleÅŸtirme DetaylarÄ±:**")
                    for col, method in anonymization_report['method_used'].items():
                        method_name = "SayÄ±sal Hash" if method == 'numeric_hash' else "Metin Hash"
                        st.markdown(f"- `{col}`: {method_name}")
            
            # Analiz butonu
            if st.button("ğŸš€ Toplu Analiz BaÅŸlat", use_container_width=True):
                with st.spinner("ğŸ”„ Analiz ediliyor..."):
                    results = []
                    
                    # Progress bar
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, row in df.iterrows():
                        features = row.to_dict()
                        result = predict_exoplanet(
                            features,
                            model,
                            scaler,
                            feature_names,
                            anomaly_detector=anomaly_detector,
                        )
                        
                        novelty = result.get('novelty') or {}
                        novelty_flag = novelty.get('is_novel_candidate', False)
                        novelty_score = novelty.get('novelty_score')

                        results.append({
                            'SatÄ±r': idx + 1,
                            'Ã–tegezegen': 'Evet âœ…' if result['is_exoplanet'] else 'HayÄ±r âŒ',
                            'OlasÄ±lÄ±k (%)': f"{result['probability_exoplanet']*100:.2f}",
                            'GÃ¼ven (%)': f"{result['confidence']*100:.2f}",
                            'Yeni Aday': 'ğŸš¨ Evet' if novelty_flag else 'âœ… Uyumlu',
                            'Novelty Skoru': f"{novelty_score:.3f}" if novelty_score is not None else 'â€”'
                        })
                        
                        # Progress gÃ¼ncelle
                        progress = (idx + 1) / len(df)
                        progress_bar.progress(progress)
                        status_text.text(f"Ä°ÅŸleniyor: {idx + 1}/{len(df)}")
                    
                    status_text.text("âœ… Analiz tamamlandÄ±!")
                    
                    # SonuÃ§lar
                    results_df = pd.DataFrame(results)
                    
                    st.markdown("---")
                    st.header("ğŸ“Š Analiz SonuÃ§larÄ±")
                    
                    # Ä°statistikler
                    total = len(results_df)
                    exoplanets = len(results_df[results_df['Ã–tegezegen'] == 'Evet âœ…'])
                    non_exoplanets = total - exoplanets
                    avg_confidence = results_df['GÃ¼ven (%)'].str.rstrip('%').astype(float).mean()
                    new_candidate_count = (results_df['Yeni Aday'] == 'ğŸš¨ Evet').sum()
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Toplam Analiz", total)
                    with col2:
                        st.metric("Ã–tegezegen Bulundu", exoplanets, f"{exoplanets/total*100:.1f}%")
                    with col3:
                        st.metric("Ã–tegezegen DeÄŸil", non_exoplanets)
                    with col4:
                        st.metric("Ortalama GÃ¼ven", f"{avg_confidence:.2f}%")

                    extra_col1, extra_col2 = st.columns(2)
                    with extra_col1:
                        st.metric("Yeni Aday SayÄ±sÄ±", new_candidate_count)
                    with extra_col2:
                        novel_ratio = (new_candidate_count / total * 100) if total > 0 else 0
                        st.metric("Novelty OranÄ±", f"{novel_ratio:.2f}%")
                    
                    # Pasta grafiÄŸi
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig = go.Figure(data=[go.Pie(
                            labels=['Ã–tegezegen', 'Ã–tegezegen DeÄŸil'],
                            values=[exoplanets, non_exoplanets],
                            marker_colors=['#38ef7d', '#ff6a00'],
                            hole=0.4
                        )])
                        fig.update_layout(title="SonuÃ§ DaÄŸÄ±lÄ±mÄ±")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # GÃ¼ven skoru histogramÄ±
                        confidence_values = results_df['GÃ¼ven (%)'].str.rstrip('%').astype(float)
                        fig = go.Figure(data=[go.Histogram(
                            x=confidence_values,
                            nbinsx=20,
                            marker_color='lightblue'
                        )])
                        fig.update_layout(
                            title="GÃ¼ven Skoru DaÄŸÄ±lÄ±mÄ±",
                            xaxis_title="GÃ¼ven (%)",
                            yaxis_title="Frekans"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # DetaylÄ± sonuÃ§lar tablosu
                    st.subheader("ğŸ“‹ DetaylÄ± SonuÃ§lar")
                    st.dataframe(results_df, use_container_width=True)

                    if new_candidate_count > 0:
                        st.markdown("### ğŸ§­ Potansiyel Yeni Adaylar")
                        novel_subset = results_df[results_df['Yeni Aday'] == 'ğŸš¨ Evet']
                        st.dataframe(novel_subset, use_container_width=True)
                    
                    # Ä°ndirme butonu
                    csv = results_df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ SonuÃ§larÄ± Ä°ndir (CSV)",
                        data=csv,
                        file_name=f"exoplanet_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
        
        except Exception as e:
            st.error(f"âŒ Hata: {e}")
            st.info("â„¹ï¸ LÃ¼tfen geÃ§erli bir CSV dosyasÄ± yÃ¼kleyin.")


def show_data_generation_page():
    """Sentetik veri Ã¼retim sayfasÄ±"""
    st.header("ğŸ§ª Sentetik Veri Ãœretimi LaboratuvarÄ±")
    st.markdown(
        "GerÃ§ek Kepler daÄŸÄ±lÄ±mÄ±nÄ± koruyarak yeni Ã¶tegezegen adaylarÄ± Ã¼retin, senaryolarÄ± test edin "
        "ve modelinizi zenginleÅŸtirin."
    )

    st.markdown("---")

    col1, col2, col3 = st.columns([2, 2, 1])
    with col1:
        data_source = st.selectbox(
            "ğŸ“ Referans Veri KaynaÄŸÄ±",
            ["VarsayÄ±lan Kepler Verisi", "CSV YÃ¼kle"],
        )
    with col2:
        strategy = st.selectbox(
            "ğŸ§  Ãœretim Stratejisi",
            [
                "Gauss KarÄ±ÅŸÄ±mÄ±",
                "SMOTE (AzÄ±nlÄ±k gÃ¼Ã§lendirme)",
                "Hibrit (Ã–nerilen)",
            ],
            index=2,
        )
    with col3:
        random_state = st.number_input(
            "ğŸ”¢ Rastgele Tohum",
            min_value=0,
            max_value=9999,
            value=42,
        )

    reference_df = None

    try:
        if data_source == "VarsayÄ±lan Kepler Verisi":
            reference_df = load_default_reference_dataframe().copy()
        else:
            uploaded_file = st.file_uploader(
                "ğŸ“¤ Ã–zellikleri iÃ§eren CSV dosyasÄ± yÃ¼kleyin",
                type=["csv"],
                help="Dosya 'koi_disposition' veya 'is_exoplanet' sÃ¼tununu iÃ§ermelidir.",
            )
            if uploaded_file is not None:
                raw_df = pd.read_csv(uploaded_file)
                features, labels = prepare_features_from_dataframe(raw_df)
                reference_df = pd.concat([features, labels.rename("is_exoplanet")], axis=1)
            else:
                st.info("â„¹ï¸ VarsayÄ±lan veri seti kullanÄ±lacak.")
                reference_df = load_default_reference_dataframe().copy()
    except Exception as exc:
        st.error(f"Veri yÃ¼klenirken sorun oluÅŸtu: {exc}")
        return

    if reference_df is None or reference_df.empty:
        st.warning("GÃ¶sterilecek veri bulunamadÄ±.")
        return

    X_reference = reference_df.drop(columns="is_exoplanet")
    y_reference = reference_df["is_exoplanet"]

    confirmed_ratio = y_reference.mean() * 100
    st.markdown("### ğŸ“ˆ Referans Veri Ã–zeti")
    m1, m2, m3, m4 = st.columns(4)
    with m1:
        st.metric("Toplam Ã–rnek", f"{len(reference_df):,}")
    with m2:
        st.metric("Ã–zellik SayÄ±sÄ±", len(X_reference.columns))
    with m3:
        st.metric("CONFIRMED OranÄ±", f"{confirmed_ratio:.2f}%")
    with m4:
        st.metric("FALSE/DiÄŸer", f"{100 - confirmed_ratio:.2f}%")

    st.markdown("---")

    with st.form("synthetic_generation_form"):
        st.subheader("âš™ï¸ Ãœretim Parametreleri")
        col_left, col_right = st.columns(2)
        with col_left:
            sample_count = st.slider(
                "Ãœretilecek Ã¶rnek sayÄ±sÄ±",
                min_value=200,
                max_value=10000,
                step=100,
                value=2000,
            )
            include_labels = st.checkbox(
                "Ã‡Ä±ktÄ±ya 'is_exoplanet' etiketini ekle",
                value=True,
            )
        with col_right:
            target_exoplanet_ratio = st.slider(
                "Hedef Ã¶tegezegen oranÄ± (%)",
                min_value=10,
                max_value=90,
                value=int(np.clip(confirmed_ratio, 15, 60)),
                help="Ã‡Ä±ktÄ± veri setinde Ã¶tegezegenlerin payÄ±.",
            )
            quality_clip = st.checkbox(
                "AykÄ±rÄ± deÄŸerleri otomatik sÄ±nÄ±rla",
                value=True,
            )

        submitted = st.form_submit_button("ğŸš€ Sentetik Veriyi Ãœret", use_container_width=True)

    if not submitted:
        st.info("Parametreleri seÃ§ip 'Sentetik Veriyi Ãœret' butonuna tÄ±klayÄ±n.")
        return

    with st.spinner("ğŸ§ª Veri Ã¼retiliyor..."):
        generator = ExoplanetDataGenerator(random_state=random_state)
        generator.fit(X_reference, y_reference)

        class_ratio = {
            1: target_exoplanet_ratio / 100,
            0: 1 - (target_exoplanet_ratio / 100),
        }

        strategy_map = {
            "Gauss KarÄ±ÅŸÄ±mÄ±": "gaussian",
            "SMOTE (AzÄ±nlÄ±k gÃ¼Ã§lendirme)": "smote",
            "Hibrit (Ã–nerilen)": "hybrid",
        }

        synthetic_df = generator.generate_dataset(
            n_samples=sample_count,
            strategy=strategy_map[strategy],
            class_ratio=class_ratio,
            include_labels=include_labels,
        )

    st.success(
        f"âœ… {len(synthetic_df):,} satÄ±rlÄ±k sentetik veri baÅŸarÄ±yla Ã¼retildi!"
    )

    if quality_clip:
        numeric_cols = synthetic_df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col == "is_exoplanet":
                continue
            if col not in reference_df.columns:
                continue
            q1 = reference_df[col].quantile(0.01)
            q3 = reference_df[col].quantile(0.99)
            synthetic_df[col] = synthetic_df[col].clip(q1, q3)

    st.markdown("### ğŸ“Š Sentetik Veri Ã–zeti")
    col_summary, col_chart = st.columns([1.2, 1])
    with col_summary:
        synth_ratio = (
            synthetic_df["is_exoplanet"].mean() * 100
            if "is_exoplanet" in synthetic_df.columns
            else target_exoplanet_ratio
        )
        st.metric("Ã–tegezegen OranÄ±", f"{synth_ratio:.2f}%")
        st.metric("Ã–rnek SayÄ±sÄ±", f"{len(synthetic_df):,}")
        st.metric("Strateji", strategy)
    with col_chart:
        if "is_exoplanet" in synthetic_df.columns:
            ratio_fig = go.Figure(
                data=[
                    go.Pie(
                        labels=["Ã–tegezegen", "DiÄŸer"],
                        values=[synth_ratio, 100 - synth_ratio],
                        hole=0.55,
                        marker_colors=["#38ef7d", "#ff6a00"],
                    )
                ]
            )
            ratio_fig.update_layout(height=240, margin=dict(l=0, r=0, t=40, b=0))
            st.plotly_chart(ratio_fig, use_container_width=True)

    st.markdown("---")

    st.markdown("### ğŸ” Ä°lk 10 SatÄ±r")
    st.dataframe(synthetic_df.head(10), use_container_width=True)

    csv_buffer = BytesIO()
    synthetic_df.to_csv(csv_buffer, index=False)
    csv_buffer.seek(0)

    st.download_button(
        label="ğŸ“¥ Sentetik Veriyi Ä°ndir",
        data=csv_buffer,
        file_name=f"synthetic_exoplanets_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
    )

    st.markdown("### ğŸ“ˆ Ã–zellik DaÄŸÄ±lÄ±mÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    comparison_cols = st.multiselect(
        "KarÅŸÄ±laÅŸtÄ±rÄ±lacak Ã¶zellikler",
        options=list(X_reference.columns),
        default=["koi_period", "koi_prad", "koi_teq"],
    )

    if comparison_cols:
        tabs = st.tabs([f"ğŸ“Œ {col}" for col in comparison_cols])
        for tab, feature in zip(tabs, comparison_cols):
            with tab:
                fig = go.Figure()
                fig.add_trace(
                    go.Box(
                        y=reference_df[feature],
                        name="Referans",
                        marker_color="#2a5298",
                    )
                )
                fig.add_trace(
                    go.Box(
                        y=synthetic_df[feature],
                        name="Sentetik",
                        marker_color="#38ef7d",
                    )
                )
                fig.update_layout(height=400, showlegend=True)
                st.plotly_chart(fig, use_container_width=True)

def show_model_analysis_page(model, scaler, feature_names, anomaly_detector):
    """Model analizi sayfasÄ±"""
    st.header("ğŸ§  Model Performans Analizi")
    st.markdown("EÄŸitilmiÅŸ modelin detaylÄ± performans analizi ve Ã¶zellik Ã¶nem dereceleri.")
    
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“ˆ Performans Metrikleri",
        "â­ Ã–zellik Analizi",
        "ğŸ“Š Model DetaylarÄ±",
        "ğŸ§­ Novelty Ä°zleme",
    ])
    
    with tab1:
        st.subheader("ğŸ“Š Model Performans Metrikleri")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("DoÄŸruluk", "94.46%", "4.46%")
        with col2:
            st.metric("Kesinlik", "87.86%", "2.14%")
        with col3:
            st.metric("DuyarlÄ±lÄ±k", "93.62%", "3.62%")
        with col4:
            st.metric("F1 Skoru", "0.9065", "0.0065")
        with col5:
            st.metric("ROC AUC", "0.9839", "0.0839")
        
        st.markdown("---")
        
        # KarmaÅŸÄ±klÄ±k matrisi
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ¯ KarmaÅŸÄ±klÄ±k Matrisi**")
            cm_data = np.array([[1293, 71], [35, 514]])
            
            fig = go.Figure(data=go.Heatmap(
                z=cm_data,
                x=['Tahmin: HayÄ±r', 'Tahmin: Evet'],
                y=['GerÃ§ek: HayÄ±r', 'GerÃ§ek: Evet'],
                text=cm_data,
                texttemplate="%{text}",
                colorscale='Blues',
                showscale=False
            ))
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            st.info("""
            **AÃ§Ä±klama:**
            - **TN (1293):** DoÄŸru negatif - DoÄŸru ÅŸekilde 'deÄŸil' dendi
            - **FP (71):** YanlÄ±ÅŸ pozitif - YanlÄ±ÅŸlÄ±kla 'Ã¶tegezegen' dendi
            - **FN (35):** YanlÄ±ÅŸ negatif - KaÃ§Ä±rÄ±lan Ã¶tegezegen
            - **TP (514):** DoÄŸru pozitif - DoÄŸru tespit edilen Ã¶tegezegen
            """)
        
        with col2:
            st.markdown("**ğŸ“Š Metrik KarÅŸÄ±laÅŸtÄ±rmasÄ±**")
            metrics_data = {
                'Metrik': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'],
                'DeÄŸer': [0.9446, 0.8786, 0.9362, 0.9065, 0.9839]
            }
            
            fig = go.Figure(data=[
                go.Bar(
                    x=metrics_data['Metrik'],
                    y=metrics_data['DeÄŸer'],
                    marker_color=['#667eea', '#764ba2', '#667eea', '#764ba2', '#667eea'],
                    text=[f"{v:.4f}" for v in metrics_data['DeÄŸer']],
                    textposition='auto'
                )
            ])
            fig.update_layout(
                yaxis_range=[0, 1],
                height=400,
                showlegend=False
            )
            fig.add_hline(y=0.9, line_dash="dash", line_color="red", annotation_text="90% Hedef")
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("â­ Ã–zellik Ã–nem Dereceleri")
        
        # Ã–zellik Ã¶nem dereceleri
        feature_importance = pd.DataFrame({
            'Ã–zellik': feature_names,
            'Ã–nem': model.feature_importances_
        }).sort_values('Ã–nem', ascending=False)
        
        # Top 15 grafik
        col1, col2 = st.columns([2, 1])
        
        with col1:
            fig = go.Figure(data=[
                go.Bar(
                    y=feature_importance['Ã–zellik'].head(15),
                    x=feature_importance['Ã–nem'].head(15),
                    orientation='h',
                    marker_color='coral',
                    text=feature_importance['Ã–nem'].head(15).round(4),
                    textposition='auto'
                )
            ])
            fig.update_layout(
                title="En Ã–nemli 15 Ã–zellik",
                xaxis_title="Ã–nem Derecesi",
                yaxis_title="Ã–zellik",
                height=600
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("**ğŸ“Š Top 10 Ã–zellikler**")
            for idx, row in feature_importance.head(10).iterrows():
                st.metric(
                    row['Ã–zellik'],
                    f"{row['Ã–nem']:.4f}",
                    delta=f"#{feature_importance.index.get_loc(idx) + 1}"
                )
        
        # Tam tablo
        st.markdown("---")
        st.markdown("**ğŸ“‹ TÃ¼m Ã–zellikler**")
        st.dataframe(feature_importance, use_container_width=True)
        
        # Ã–zellik Ã¶nem daÄŸÄ±lÄ±mÄ±
        fig = go.Figure(data=[go.Histogram(
            x=feature_importance['Ã–nem'],
            nbinsx=20,
            marker_color='lightgreen'
        )])
        fig.update_layout(
            title="Ã–zellik Ã–nem Derecesi DaÄŸÄ±lÄ±mÄ±",
            xaxis_title="Ã–nem Derecesi",
            yaxis_title="Frekans"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("ğŸ”§ Model DetaylarÄ±")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="info-box">
                <h3>ğŸ¤– Model Bilgileri</h3>
                <ul>
                    <li><strong>Algoritma:</strong> XGBoost Classifier</li>
                    <li><strong>N Estimators:</strong> 300</li>
                    <li><strong>Max Depth:</strong> 7</li>
                    <li><strong>Learning Rate:</strong> 0.05</li>
                    <li><strong>Subsample:</strong> 0.8</li>
                    <li><strong>Colsample Bytree:</strong> 0.8</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="success-box">
                <h3>ğŸ“Š Veri Bilgileri</h3>
                <ul>
                    <li><strong>Toplam Veri:</strong> 9,564 Ã¶rneklem</li>
                    <li><strong>EÄŸitim Seti:</strong> 7,651 Ã¶rneklem (80%)</li>
                    <li><strong>Test Seti:</strong> 1,913 Ã¶rneklem (20%)</li>
                    <li><strong>Ã–zellik SayÄ±sÄ±:</strong> 23</li>
                    <li><strong>Dengeleme:</strong> SMOTE + Undersampling</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="warning-box">
                <h3>âš™ï¸ Ã–n Ä°ÅŸleme</h3>
                <ul>
                    <li><strong>Ã–lÃ§eklendirme:</strong> Robust Scaler</li>
                    <li><strong>Eksik Veri:</strong> Medyan ile doldurma</li>
                    <li><strong>Ã–zellik MÃ¼hendisliÄŸi:</strong> 5 yeni Ã¶zellik</li>
                    <li><strong>Dengeleme OranÄ±:</strong> 1.25:1</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="info-box">
                <h3>ğŸ¯ Hedef DaÄŸÄ±lÄ±mÄ±</h3>
                <ul>
                    <li><strong>CONFIRMED:</strong> 2,746 (28.7%)</li>
                    <li><strong>FALSE POSITIVE:</strong> 4,839 (50.6%)</li>
                    <li><strong>CANDIDATE:</strong> 1,979 (20.7%)</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)

    with tab4:
        st.subheader("ğŸ§­ Anomali TabanlÄ± Yeni Aday Takibi")

        if anomaly_detector is None:
            st.info(
                "IsolationForest modeli bulunamadÄ±. LÃ¼tfen `python main.py` komutu ile anomali modelini eÄŸitip `anomaly_detector.pkl` dosyasÄ±nÄ± oluÅŸturun."
            )
            return

        default_path = Path('cumulative_2025.10.04_09.55.40.csv')
        try:
            if default_path.exists():
                reference_raw = pd.read_csv(default_path, comment='#')
            else:
                reference_raw = load_default_reference_dataframe()

            scoring = score_catalog(reference_raw, model, scaler, list(feature_names), anomaly_detector)
            scored_reference = scoring['scored']

            novel_df = scored_reference[scored_reference.get('is_novel_candidate', False)].copy()
            total_ref = len(scored_reference)
            novel_count = len(novel_df)
            avg_novelty = float(scored_reference.get('novelty_score', pd.Series(dtype=float)).mean())

            metric_col1, metric_col2, metric_col3 = st.columns(3)
            with metric_col1:
                st.metric("Referans kayÄ±t", f"{total_ref:,}")
            with metric_col2:
                st.metric("Yeni aday", f"{novel_count:,}")
            with metric_col3:
                st.metric("Ortalama novelty", f"{avg_novelty:.3f}" if not np.isnan(avg_novelty) else "â€”")

            if novel_count:
                st.markdown("### ğŸš¨ Ã–ne Ã§Ä±kan anomaliler")
                display_cols = [
                    col
                    for col in [
                        'koi_name',
                        'koi_period',
                        'koi_prad',
                        'koi_teq',
                        'model_probability',
                        'novelty_score',
                        'koi_disposition',
                    ]
                    if col in novel_df.columns
                ]
                st.dataframe(
                    novel_df.sort_values('novelty_score').head(25)[display_cols],
                    use_container_width=True,
                )
            else:
                st.success("Referans veri kÃ¼mesinde daÄŸÄ±lÄ±m dÄ±ÅŸÄ± gÃ¼Ã§lÃ¼ aday bulunmadÄ±.")

            if {'koi_period', 'koi_model_snr', 'novelty_score'}.issubset(scored_reference.columns):
                st.markdown("### ğŸ” Novelty daÄŸÄ±lÄ±mÄ±")
                fig = px.scatter(
                    scored_reference,
                    x='koi_period',
                    y='koi_model_snr',
                    color='novelty_score',
                    color_continuous_scale='Viridis',
                    hover_data=['koi_disposition'] if 'koi_disposition' in scored_reference.columns else None,
                    height=500,
                )
                if novel_count:
                    fig.add_trace(
                        go.Scatter(
                            x=novel_df['koi_period'],
                            y=novel_df['koi_model_snr'],
                            mode='markers',
                            marker=dict(color='#ff4d4f', size=10, symbol='x'),
                            name='Yeni aday',
                        )
                    )
                fig.update_layout(xaxis_title='YÃ¶rÃ¼nge periyodu (gÃ¼n)', yaxis_title='Model SNR')
                st.plotly_chart(fig, use_container_width=True)

            csv_buffer = BytesIO()
            scored_reference.to_csv(csv_buffer, index=False)
            csv_buffer.seek(0)
            st.download_button(
                label="ğŸ“¥ Novelty raporunu indir",
                data=csv_buffer,
                file_name=f"novelty_snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
            )

        except Exception as exc:
            st.error(f"Referans verisi analiz edilirken hata oluÅŸtu: {exc}")


def show_about_page():
    """HakkÄ±nda sayfasÄ±"""
    st.header("ğŸ“š Ã–tegezegen KeÅŸif Sistemi HakkÄ±nda")
    
    st.markdown("""
    ## ğŸŒŒ Proje Ã–zeti
    
    Bu proje, NASA'nÄ±n Kepler uzay teleskobundan elde edilen verileri kullanarak 
    Ã¶tegezegenleri otomatik olarak tespit eden bir yapay zeka sistemidir.
    
    ### âœ¨ Ã–zellikler
    
    - **ğŸ¤– XGBoost AlgoritmasÄ±:** YÃ¼ksek doÄŸruluklu gradient boosting
    - **ğŸ§  XAI (Explainable AI):** SHAP ve LIME ile aÃ§Ä±klanabilir tahminler
    - **ğŸ“Š Streamlit ArayÃ¼zÃ¼:** Modern ve kullanÄ±cÄ± dostu web arayÃ¼zÃ¼
    - **ğŸ“ˆ GerÃ§ek ZamanlÄ± Analiz:** AnÄ±nda tahmin ve aÃ§Ä±klama
    - **ğŸ“ Toplu Ä°ÅŸleme:** CSV dosyasÄ± ile birden fazla tahmin
    
    ### ğŸ¯ Performans
    
    - **DoÄŸruluk:** %94.46
    - **F1 Skoru:** 0.9065
    - **ROC AUC:** 0.9839
    - **Test Seti:** 1,913 Ã¶rneklem
    
    ### ğŸ”¬ Teknolojiler
    
    - Python 3.10+
    - XGBoost
    - SHAP & LIME
    - Streamlit
    - Plotly
    - Scikit-learn
    - Pandas & NumPy
    
    ### ğŸ“Š Veri Seti
    
    **NASA Exoplanet Archive - Kepler Cumulative Dataset**
    - 9,564 gezegen adayÄ±
    - 141 Ã¶zellik
    - 2,746 doÄŸrulanmÄ±ÅŸ Ã¶tegezegen
    
    ### ğŸ‘¥ KullanÄ±m AlanlarÄ±
    
    1. **AraÅŸtÄ±rmacÄ±lar:** Yeni gezegen adaylarÄ±nÄ± hÄ±zlÄ±ca deÄŸerlendirme
    2. **Ã–ÄŸrenciler:** Makine Ã¶ÄŸrenimi ve astrofizik eÄŸitimi
    3. **MeraklÄ±lar:** Ã–tegezegen keÅŸfini anlama ve deneyimleme
    
    ### ğŸš€ GeliÅŸtirmeler
    
    - (Planlanan) K2 ve TESS veri setleri desteÄŸi
    - Derin Ã¶ÄŸrenme modelleri
    - API entegrasyonu
    - GerÃ§ek zamanlÄ± veri akÄ±ÅŸÄ±
    
    ### ğŸ“– Kaynaklar
    
    - [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/)
    - [Kepler Mission](https://www.nasa.gov/mission_pages/kepler/main/index.html)
    - [XGBoost Documentation](https://xgboost.readthedocs.io/)
    - [SHAP Documentation](https://shap.readthedocs.io/)
    
    ### ğŸ“§ Ä°letiÅŸim
    
    SorularÄ±nÄ±z iÃ§in GitHub Ã¼zerinden issue aÃ§abilirsiniz.
    
    ---
    
    **ğŸŒŒ Evrenin gizemlerini keÅŸfetmeye devam edin! ğŸŒŒ**
    """)
    
    # Son gÃ¼ncelleme
    st.info(f"ğŸ“… Son GÃ¼ncelleme: {datetime.now().strftime('%d.%m.%Y')}")
    
    # TeÅŸekkÃ¼rler
    st.success("""
    ğŸ™ **TeÅŸekkÃ¼rler**
    
    - NASA Kepler ekibine veri seti iÃ§in
    - AÃ§Ä±k kaynak topluluÄŸuna harika araÃ§lar iÃ§in
    - Sizlere ilginiz iÃ§in!
    """)

if __name__ == "__main__":
    main()
